{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-17 19:58:41.918444: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-17 19:58:41.973653: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-17 19:58:41.974726: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-17 19:58:42.789088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2, 381), (2, 381))\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 760 entries, 0 to 759\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   NAME                 760 non-null    object \n",
      " 1   date                 760 non-null    int64  \n",
      " 2   color_and_value      760 non-null    object \n",
      " 3   name_code            760 non-null    int64  \n",
      " 4   day_of_month         760 non-null    int32  \n",
      " 5   day_of_week          760 non-null    int32  \n",
      " 6   date_code            760 non-null    int64  \n",
      " 7   day_of_year          760 non-null    int64  \n",
      " 8   value                760 non-null    float64\n",
      " 9   color                760 non-null    object \n",
      " 10  extra                760 non-null    float64\n",
      " 11  color_code           760 non-null    int64  \n",
      " 12  next_color_code      758 non-null    float64\n",
      " 13  previous_color_code  758 non-null    float64\n",
      " 14  color_binary         760 non-null    int64  \n",
      " 15  next_color_binary    758 non-null    float64\n",
      " 16  color_group          760 non-null    int64  \n",
      " 17  next_color_group     758 non-null    float64\n",
      "dtypes: float64(6), int32(2), int64(7), object(3)\n",
      "memory usage: 101.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>date</th>\n",
       "      <th>color_and_value</th>\n",
       "      <th>name_code</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>date_code</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>value</th>\n",
       "      <th>color</th>\n",
       "      <th>extra</th>\n",
       "      <th>color_code</th>\n",
       "      <th>next_color_code</th>\n",
       "      <th>previous_color_code</th>\n",
       "      <th>color_binary</th>\n",
       "      <th>next_color_binary</th>\n",
       "      <th>color_group</th>\n",
       "      <th>next_color_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CJ1</td>\n",
       "      <td>1733702400000000000</td>\n",
       "      <td>0.42857 | FF0000 | 184733</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "      <td>0.42857</td>\n",
       "      <td>FF0000</td>\n",
       "      <td>184733.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CJ2</td>\n",
       "      <td>1733702400000000000</td>\n",
       "      <td>0.0 | FF9900 | 1224919</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>FF9900</td>\n",
       "      <td>1224919.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CJ1</td>\n",
       "      <td>1733961600000000000</td>\n",
       "      <td>0.28571 | D5A6BD | 167139</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>0.28571</td>\n",
       "      <td>D5A6BD</td>\n",
       "      <td>167139.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CJ2</td>\n",
       "      <td>1733961600000000000</td>\n",
       "      <td>-0.1429 | 00FF00 | 1091707</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>-0.14290</td>\n",
       "      <td>00FF00</td>\n",
       "      <td>1091707.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CJ1</td>\n",
       "      <td>1734048000000000000</td>\n",
       "      <td>0.28571 | FF9900 | 138497</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>348</td>\n",
       "      <td>0.28571</td>\n",
       "      <td>FF9900</td>\n",
       "      <td>138497.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>CJ2</td>\n",
       "      <td>1716940800100000000</td>\n",
       "      <td>11.7143 | FFFF00 | 1117856</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>150</td>\n",
       "      <td>11.71430</td>\n",
       "      <td>FFFF00</td>\n",
       "      <td>1117856.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>CJ1</td>\n",
       "      <td>1717027200100000000</td>\n",
       "      <td>15.5714 | 00FF00 | 61845</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>378</td>\n",
       "      <td>151</td>\n",
       "      <td>15.57140</td>\n",
       "      <td>00FF00</td>\n",
       "      <td>61845.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>CJ2</td>\n",
       "      <td>1717027200100000000</td>\n",
       "      <td>11.5714 | FF9900 | 1280565</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>378</td>\n",
       "      <td>151</td>\n",
       "      <td>11.57140</td>\n",
       "      <td>FF9900</td>\n",
       "      <td>1280565.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>CJ1</td>\n",
       "      <td>1717113600100000000</td>\n",
       "      <td>15.5714 | FFFF00 | 58560</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>379</td>\n",
       "      <td>152</td>\n",
       "      <td>15.57140</td>\n",
       "      <td>FFFF00</td>\n",
       "      <td>58560.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>CJ2</td>\n",
       "      <td>1717113600100000000</td>\n",
       "      <td>11.4286 | 00FF00 | 1296267</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>379</td>\n",
       "      <td>152</td>\n",
       "      <td>11.42860</td>\n",
       "      <td>00FF00</td>\n",
       "      <td>1296267.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    NAME                 date             color_and_value  name_code  \\\n",
       "0    CJ1  1733702400000000000   0.42857 | FF0000 | 184733          1   \n",
       "1    CJ2  1733702400000000000      0.0 | FF9900 | 1224919          2   \n",
       "2    CJ1  1733961600000000000   0.28571 | D5A6BD | 167139          1   \n",
       "3    CJ2  1733961600000000000  -0.1429 | 00FF00 | 1091707          2   \n",
       "4    CJ1  1734048000000000000   0.28571 | FF9900 | 138497          1   \n",
       "..   ...                  ...                         ...        ...   \n",
       "755  CJ2  1716940800100000000  11.7143 | FFFF00 | 1117856          2   \n",
       "756  CJ1  1717027200100000000    15.5714 | 00FF00 | 61845          1   \n",
       "757  CJ2  1717027200100000000  11.5714 | FF9900 | 1280565          2   \n",
       "758  CJ1  1717113600100000000    15.5714 | FFFF00 | 58560          1   \n",
       "759  CJ2  1717113600100000000  11.4286 | 00FF00 | 1296267          2   \n",
       "\n",
       "     day_of_month  day_of_week  date_code  day_of_year     value   color  \\\n",
       "0               9            0          0          344   0.42857  FF0000   \n",
       "1               9            0          0          344   0.00000  FF9900   \n",
       "2              12            3          1          347   0.28571  D5A6BD   \n",
       "3              12            3          1          347  -0.14290  00FF00   \n",
       "4              13            4          2          348   0.28571  FF9900   \n",
       "..            ...          ...        ...          ...       ...     ...   \n",
       "755            29            2        377          150  11.71430  FFFF00   \n",
       "756            30            3        378          151  15.57140  00FF00   \n",
       "757            30            3        378          151  11.57140  FF9900   \n",
       "758            31            4        379          152  15.57140  FFFF00   \n",
       "759            31            4        379          152  11.42860  00FF00   \n",
       "\n",
       "         extra  color_code  next_color_code  previous_color_code  \\\n",
       "0     184733.0           0              2.0                  NaN   \n",
       "1    1224919.0           1              3.0                  NaN   \n",
       "2     167139.0           2              1.0                  0.0   \n",
       "3    1091707.0           3              1.0                  1.0   \n",
       "4     138497.0           1              0.0                  2.0   \n",
       "..         ...         ...              ...                  ...   \n",
       "755  1117856.0           4              1.0                  0.0   \n",
       "756    61845.0           3              4.0                  3.0   \n",
       "757  1280565.0           1              3.0                  4.0   \n",
       "758    58560.0           4              NaN                  3.0   \n",
       "759  1296267.0           3              NaN                  1.0   \n",
       "\n",
       "     color_binary  next_color_binary  color_group  next_color_group  \n",
       "0               1                0.0            1               6.0  \n",
       "1               0                1.0            5               2.0  \n",
       "2               0                0.0            6               5.0  \n",
       "3               1                0.0            2               5.0  \n",
       "4               0                1.0            5               1.0  \n",
       "..            ...                ...          ...               ...  \n",
       "755             1                0.0            3               5.0  \n",
       "756             1                1.0            2               3.0  \n",
       "757             0                1.0            5               2.0  \n",
       "758             1                NaN            3               NaN  \n",
       "759             1                NaN            2               NaN  \n",
       "\n",
       "[760 rows x 18 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Pandas library\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.tensorflow_model import TensorFlowModel\n",
    "\n",
    "model = TensorFlowModel()\n",
    "path = \"../test_data/new_data.xlsx\"\n",
    "\n",
    "coded_df = model.process_excel(path)\n",
    "\n",
    "\n",
    "print(coded_df.info())\n",
    "coded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_code</th>\n",
       "      <th>name_code</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>color_code</th>\n",
       "      <th>value</th>\n",
       "      <th>color_group</th>\n",
       "      <th>extra</th>\n",
       "      <th>next_color_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.42857</td>\n",
       "      <td>1</td>\n",
       "      <td>184733.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>344</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5</td>\n",
       "      <td>1224919.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.28571</td>\n",
       "      <td>6</td>\n",
       "      <td>167139.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>347</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.14290</td>\n",
       "      <td>2</td>\n",
       "      <td>1091707.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>348</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.28571</td>\n",
       "      <td>5</td>\n",
       "      <td>138497.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>377</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11.71430</td>\n",
       "      <td>3</td>\n",
       "      <td>1117856.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>378</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15.57140</td>\n",
       "      <td>2</td>\n",
       "      <td>61845.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>378</td>\n",
       "      <td>2</td>\n",
       "      <td>151</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11.57140</td>\n",
       "      <td>5</td>\n",
       "      <td>1280565.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>379</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>15.57140</td>\n",
       "      <td>3</td>\n",
       "      <td>58560.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>379</td>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>11.42860</td>\n",
       "      <td>2</td>\n",
       "      <td>1296267.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_code  name_code  day_of_year  day_of_month  day_of_week  color_code  \\\n",
       "0            0          1          344             9            0           0   \n",
       "1            0          2          344             9            0           1   \n",
       "2            1          1          347            12            3           2   \n",
       "3            1          2          347            12            3           3   \n",
       "4            2          1          348            13            4           1   \n",
       "..         ...        ...          ...           ...          ...         ...   \n",
       "755        377          2          150            29            2           4   \n",
       "756        378          1          151            30            3           3   \n",
       "757        378          2          151            30            3           1   \n",
       "758        379          1          152            31            4           4   \n",
       "759        379          2          152            31            4           3   \n",
       "\n",
       "        value  color_group      extra  next_color_group  \n",
       "0     0.42857            1   184733.0               6.0  \n",
       "1     0.00000            5  1224919.0               2.0  \n",
       "2     0.28571            6   167139.0               5.0  \n",
       "3    -0.14290            2  1091707.0               5.0  \n",
       "4     0.28571            5   138497.0               1.0  \n",
       "..        ...          ...        ...               ...  \n",
       "755  11.71430            3  1117856.0               5.0  \n",
       "756  15.57140            2    61845.0               3.0  \n",
       "757  11.57140            5  1280565.0               2.0  \n",
       "758  15.57140            3    58560.0               NaN  \n",
       "759  11.42860            2  1296267.0               NaN  \n",
       "\n",
       "[760 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coded_df[[\"date_code\"  ,'name_code' , 'day_of_year', 'day_of_month', 'day_of_week' ,\"color_code\" , 'value' , 'color_group','extra',  'next_color_group' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(756, 8)\n",
      "(756, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "coded_df = coded_df.dropna(axis=0)\n",
    "\n",
    "\n",
    "X = coded_df[[\"date_code\"  ,'name_code' , 'day_of_year', 'day_of_month', 'day_of_week' ,\"color_group\" ,'extra', 'value']]\n",
    "\n",
    "\n",
    "y = pd.get_dummies(coded_df['color_group']).astype(int)  # One-hot encode the target\n",
    "\n",
    "y_labels = y.columns\n",
    "\n",
    "y = y.values\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "print(y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(756, 8)\n",
      "(756, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "print(y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(746, 10, 8)\n",
      "(746, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_sequences(X,y, timesteps):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(X) - timesteps):\n",
    "        sequences.append(X[i:i + timesteps])\n",
    "        labels.append(y[i + timesteps])\n",
    "    \n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "\n",
    "timesteps =10\n",
    "\n",
    "X , y = create_sequences(X,y, timesteps)\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(746, 10, 8)\n",
      "(746, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,shuffle=False)\n",
    "\n",
    "# Normalize the feature data (optional but recommended for neural networks)\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization ,Flatten\n",
    "# Define the input shape for LSTM\n",
    "\n",
    "input_shape = (timesteps, X.shape[2])\n",
    "\n",
    "model = Sequential([\n",
    "    # Flatten the input before feeding into Dense layers\n",
    "    Flatten(input_shape=input_shape),\n",
    "\n",
    "    # First dense layer with Batch Normalization and Dropout\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),  # Dropout for regularization\n",
    "\n",
    "    # Second dense layer with Batch Normalization and Dropout\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),  # Dropout for regularization\n",
    "\n",
    "    # Third dense layer with Batch Normalization and Dropout\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),  # Dropout for regularization\n",
    "\n",
    "    # Fourth dense layer with Batch Normalization and Dropout\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),  # Dropout for regularization\n",
    "\n",
    "    # Output layer\n",
    "    Dense(y_test.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "60/60 [==============================] - 2s 6ms/step - loss: 2.4759 - accuracy: 0.1829\n",
      "Epoch 2/60\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 2.2846 - accuracy: 0.2265\n",
      "Epoch 3/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 2.1266 - accuracy: 0.2064\n",
      "Epoch 4/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 2.0472 - accuracy: 0.2299\n",
      "Epoch 5/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 2.0204 - accuracy: 0.2349\n",
      "Epoch 6/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.9143 - accuracy: 0.2500\n",
      "Epoch 7/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.8381 - accuracy: 0.2483\n",
      "Epoch 8/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.8386 - accuracy: 0.2567\n",
      "Epoch 9/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.8597 - accuracy: 0.2500\n",
      "Epoch 10/60\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 1.7834 - accuracy: 0.2617\n",
      "Epoch 11/60\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 1.7679 - accuracy: 0.2819\n",
      "Epoch 12/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7682 - accuracy: 0.2836\n",
      "Epoch 13/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7510 - accuracy: 0.2987\n",
      "Epoch 14/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7794 - accuracy: 0.2584\n",
      "Epoch 15/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6902 - accuracy: 0.3171\n",
      "Epoch 16/60\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 1.7190 - accuracy: 0.3054\n",
      "Epoch 17/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7033 - accuracy: 0.2953\n",
      "Epoch 18/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7024 - accuracy: 0.2668\n",
      "Epoch 19/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6889 - accuracy: 0.3171\n",
      "Epoch 20/60\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 1.6628 - accuracy: 0.3255\n",
      "Epoch 21/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6532 - accuracy: 0.3205\n",
      "Epoch 22/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6719 - accuracy: 0.3289\n",
      "Epoch 23/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6783 - accuracy: 0.3037\n",
      "Epoch 24/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6506 - accuracy: 0.3188\n",
      "Epoch 25/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6708 - accuracy: 0.3087\n",
      "Epoch 26/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6559 - accuracy: 0.3188\n",
      "Epoch 27/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6408 - accuracy: 0.3356\n",
      "Epoch 28/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6366 - accuracy: 0.3188\n",
      "Epoch 29/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6475 - accuracy: 0.3473\n",
      "Epoch 30/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6472 - accuracy: 0.3154\n",
      "Epoch 31/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6492 - accuracy: 0.3020\n",
      "Epoch 32/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6286 - accuracy: 0.3372\n",
      "Epoch 33/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6420 - accuracy: 0.3339\n",
      "Epoch 34/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6057 - accuracy: 0.3607\n",
      "Epoch 35/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6102 - accuracy: 0.3389\n",
      "Epoch 36/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5934 - accuracy: 0.3708\n",
      "Epoch 37/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5887 - accuracy: 0.3624\n",
      "Epoch 38/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6401 - accuracy: 0.3440\n",
      "Epoch 39/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6205 - accuracy: 0.3255\n",
      "Epoch 40/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6169 - accuracy: 0.3540\n",
      "Epoch 41/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6082 - accuracy: 0.3557\n",
      "Epoch 42/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5894 - accuracy: 0.3658\n",
      "Epoch 43/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5590 - accuracy: 0.3607\n",
      "Epoch 44/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5531 - accuracy: 0.3708\n",
      "Epoch 45/60\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 1.6015 - accuracy: 0.3557\n",
      "Epoch 46/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6311 - accuracy: 0.3440\n",
      "Epoch 47/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5673 - accuracy: 0.3540\n",
      "Epoch 48/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5525 - accuracy: 0.3826\n",
      "Epoch 49/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5549 - accuracy: 0.3641\n",
      "Epoch 50/60\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 1.5505 - accuracy: 0.4128\n",
      "Epoch 51/60\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 1.5457 - accuracy: 0.3993\n",
      "Epoch 52/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5445 - accuracy: 0.3876\n",
      "Epoch 53/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5352 - accuracy: 0.3993\n",
      "Epoch 54/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5492 - accuracy: 0.3775\n",
      "Epoch 55/60\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 1.5544 - accuracy: 0.3926\n",
      "Epoch 56/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5550 - accuracy: 0.3742\n",
      "Epoch 57/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5422 - accuracy: 0.3943\n",
      "Epoch 58/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5105 - accuracy: 0.3993\n",
      "Epoch 59/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5483 - accuracy: 0.3859\n",
      "Epoch 60/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5218 - accuracy: 0.3842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f08dff1e3d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=60, batch_size=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0211 - accuracy: 0.1933\n",
      "Test Accuracy: 0.19333332777023315\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "[[0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0]]\n",
      "[[0.27988997 0.16898918 0.05197446 0.10846873 0.06159832 0.32907924]\n",
      " [0.3538922  0.14621335 0.33996788 0.04894326 0.05880439 0.05217892]\n",
      " [0.24333175 0.15974286 0.10085583 0.12792298 0.07097406 0.2971726 ]\n",
      " [0.34016716 0.18306369 0.13214795 0.09908154 0.10403444 0.14150514]\n",
      " [0.36893347 0.17771678 0.05251367 0.10720357 0.07873421 0.21489838]\n",
      " [0.68189055 0.0943647  0.03392331 0.05137706 0.03874698 0.09969737]\n",
      " [0.27495033 0.25408858 0.02951886 0.09885653 0.07279395 0.26979172]\n",
      " [0.50252324 0.07501395 0.2630272  0.02631136 0.06752949 0.06559484]\n",
      " [0.19614142 0.20175406 0.17373012 0.1757937  0.05759184 0.19498882]\n",
      " [0.15560696 0.10967501 0.5026814  0.06930616 0.07267056 0.09005997]\n",
      " [0.1836451  0.16365765 0.05585881 0.09668267 0.05538926 0.44476652]\n",
      " [0.29461938 0.02931279 0.18572775 0.03417484 0.09476104 0.36140415]\n",
      " [0.24779527 0.21307243 0.08636617 0.09004162 0.09712675 0.26559773]\n",
      " [0.49903607 0.21406196 0.05304338 0.06026119 0.08407908 0.0895182 ]\n",
      " [0.19078797 0.36022472 0.05138438 0.10451119 0.09956449 0.19352725]\n",
      " [0.37751895 0.11289918 0.11441565 0.05654413 0.1242742  0.21434787]\n",
      " [0.21875712 0.2661596  0.05754269 0.12787856 0.08539403 0.24426793]\n",
      " [0.3161199  0.08398198 0.10014576 0.04741883 0.15372996 0.29860368]\n",
      " [0.17309603 0.21468574 0.08515926 0.13390973 0.05734004 0.33580923]\n",
      " [0.2691786  0.26453945 0.14269345 0.02903624 0.17962039 0.11493184]\n",
      " [0.13530315 0.28901842 0.23188649 0.12563986 0.06938472 0.14876743]\n",
      " [0.37225384 0.16746171 0.10719982 0.04844523 0.1358274  0.16881205]\n",
      " [0.08578575 0.47390303 0.09999966 0.0720216  0.09690185 0.17138807]\n",
      " [0.24707481 0.11947086 0.23245291 0.06309902 0.1226153  0.21528706]\n",
      " [0.13460203 0.33979535 0.1963795  0.08634119 0.11862414 0.12425783]\n",
      " [0.3959366  0.23641874 0.1545318  0.04739153 0.0987044  0.06701686]\n",
      " [0.18315165 0.28144118 0.04633419 0.05522661 0.09016398 0.34368238]\n",
      " [0.43533772 0.09715576 0.3285659  0.01755954 0.07258324 0.04879785]\n",
      " [0.25002638 0.2955262  0.15508161 0.10174988 0.08036564 0.11725033]\n",
      " [0.60197806 0.12054349 0.16081701 0.0236713  0.0573512  0.03563901]\n",
      " [0.18657537 0.22714555 0.06980343 0.05350114 0.079194   0.38378045]\n",
      " [0.4605058  0.07819805 0.33806917 0.0223216  0.05495721 0.04594822]\n",
      " [0.1397295  0.34252325 0.18181044 0.05977837 0.1383095  0.13784896]\n",
      " [0.39399293 0.14692241 0.20720786 0.06803169 0.09316269 0.09068241]\n",
      " [0.18864352 0.28649068 0.08672124 0.06359521 0.14370543 0.23084392]\n",
      " [0.4697883  0.09566022 0.13628985 0.0736693  0.07428925 0.15030296]\n",
      " [0.21691428 0.21399194 0.03670948 0.07237165 0.07855496 0.3814577 ]\n",
      " [0.37804094 0.11749931 0.325978   0.02763329 0.09184737 0.05900109]\n",
      " [0.09254363 0.2879076  0.19784938 0.17180462 0.06789543 0.18199934]\n",
      " [0.12199117 0.19049437 0.47935617 0.04554793 0.08109204 0.08151834]\n",
      " [0.11716519 0.18429494 0.20965946 0.12601984 0.05401285 0.30884776]\n",
      " [0.3652852  0.12333535 0.23794946 0.06065168 0.09457027 0.11820793]\n",
      " [0.22913253 0.36605734 0.04098956 0.04596487 0.12137462 0.19648115]\n",
      " [0.535833   0.23515204 0.0452932  0.06233875 0.064277   0.05710588]\n",
      " [0.15574129 0.55445325 0.0333091  0.04184278 0.1254614  0.08919208]\n",
      " [0.12640998 0.36306965 0.2616608  0.05564032 0.12328379 0.06993546]\n",
      " [0.08687687 0.33627847 0.18814693 0.14095326 0.08073784 0.16700658]\n",
      " [0.07883274 0.14774151 0.29941937 0.07400435 0.13520548 0.26479653]\n",
      " [0.08263908 0.32397515 0.17311443 0.13417204 0.0591972  0.22690204]\n",
      " [0.25284427 0.19502604 0.3480511  0.03352006 0.09843066 0.07212796]\n",
      " [0.09938361 0.27580383 0.27109537 0.13050997 0.05485617 0.16835113]\n",
      " [0.11262987 0.35013744 0.31440267 0.05568263 0.10993555 0.05721181]\n",
      " [0.08049828 0.4617164  0.147114   0.06342601 0.10193722 0.14530806]\n",
      " [0.38919476 0.24926    0.09979509 0.0632752  0.09291776 0.10555724]\n",
      " [0.11789946 0.58222383 0.03521616 0.0433922  0.11791182 0.10335651]\n",
      " [0.23648918 0.334536   0.22004615 0.03044318 0.11182716 0.06665825]\n",
      " [0.12329223 0.47209942 0.06878588 0.08473779 0.10444962 0.14663509]\n",
      " [0.08371467 0.38618284 0.22872047 0.0385755  0.13942702 0.12337949]\n",
      " [0.0453751  0.4416935  0.22084028 0.0807841  0.04984512 0.16146193]\n",
      " [0.09853502 0.20471859 0.4520753  0.02626396 0.11103499 0.10737216]\n",
      " [0.06031056 0.43319747 0.263892   0.07109033 0.06414594 0.10736348]\n",
      " [0.12434673 0.29338405 0.26319733 0.05321473 0.12340267 0.14245453]\n",
      " [0.05775863 0.62578243 0.07881346 0.02684956 0.10331414 0.10748181]\n",
      " [0.15177147 0.3661844  0.23073106 0.03019445 0.12703487 0.09408373]\n",
      " [0.08015827 0.44890445 0.21550432 0.04159518 0.10396709 0.10987062]\n",
      " [0.08795984 0.2836904  0.41702867 0.0299588  0.10951266 0.07184958]\n",
      " [0.05463882 0.52179307 0.18050297 0.03468904 0.08274918 0.12562688]\n",
      " [0.32043344 0.22110757 0.27831823 0.02160275 0.09261306 0.06592499]\n",
      " [0.1879323  0.44786125 0.12358445 0.02069674 0.13986847 0.08005667]\n",
      " [0.24765429 0.3684515  0.24134234 0.02113432 0.09379048 0.02762713]\n",
      " [0.14983168 0.3466116  0.1898894  0.02246973 0.14969587 0.14150184]\n",
      " [0.199218   0.28097162 0.17081754 0.08089948 0.12210119 0.14599217]\n",
      " [0.10491757 0.36440933 0.24219882 0.05077589 0.12660597 0.1110925 ]\n",
      " [0.3210754  0.26150325 0.16590577 0.05298634 0.10500887 0.09352031]\n",
      " [0.09085903 0.31820226 0.29751056 0.08586092 0.07678146 0.13078573]\n",
      " [0.26749456 0.2528337  0.24043405 0.05884521 0.10397395 0.07641859]\n",
      " [0.06735329 0.388007   0.3149563  0.07201032 0.05661687 0.10105629]\n",
      " [0.38784596 0.17441255 0.32394868 0.01976816 0.05919062 0.03483404]\n",
      " [0.06486259 0.4967395  0.22058901 0.05419015 0.07049815 0.09312066]\n",
      " [0.10301952 0.36288744 0.35786343 0.03466079 0.09379884 0.04777005]\n",
      " [0.05550679 0.5315897  0.16604158 0.03316237 0.11409841 0.09960118]\n",
      " [0.09726157 0.34032497 0.27595654 0.04846596 0.12719971 0.1107912 ]\n",
      " [0.06140337 0.41282827 0.30748802 0.04582558 0.08235818 0.09009664]\n",
      " [0.3129727  0.2870409  0.12067427 0.05874922 0.1089627  0.11160018]\n",
      " [0.06135583 0.5562244  0.14633888 0.05675996 0.08184985 0.09747104]\n",
      " [0.2707618  0.29121608 0.2517458  0.0271984  0.09404158 0.06503623]\n",
      " [0.04435629 0.47178248 0.28759247 0.06462616 0.04913711 0.08250564]\n",
      " [0.07835943 0.34024748 0.4018162  0.02824929 0.09872814 0.05259962]\n",
      " [0.04135272 0.38750312 0.3356488  0.04933755 0.05579793 0.13035989]\n",
      " [0.07928233 0.32198536 0.39331964 0.03124097 0.09680553 0.07736608]\n",
      " [0.05552179 0.54994667 0.17856726 0.027557   0.09879936 0.08960785]\n",
      " [0.24775988 0.30571103 0.15863875 0.04456058 0.10361422 0.13971546]\n",
      " [0.06079313 0.65678495 0.10458705 0.01919016 0.10558176 0.05306291]\n",
      " [0.4383598  0.36882013 0.03718956 0.02554004 0.08028666 0.04980375]\n",
      " [0.02975819 0.65155977 0.13207121 0.04059048 0.06275588 0.08326443]\n",
      " [0.05594368 0.20433582 0.51556945 0.03312018 0.07286705 0.11816394]\n",
      " [0.02834472 0.4132818  0.3861964  0.0459306  0.04767636 0.07857017]\n",
      " [0.04526829 0.18200031 0.5043115  0.04072497 0.08212052 0.14557445]\n",
      " [0.03336304 0.40319586 0.32563475 0.03942752 0.05532641 0.14305231]\n",
      " [0.07688006 0.21719444 0.49247184 0.02469872 0.08791135 0.10084357]\n",
      " [0.05104686 0.5061229  0.24192375 0.02671188 0.091563   0.08263165]\n",
      " [0.2131796  0.2543289  0.12924235 0.03579068 0.12899455 0.23846377]\n",
      " [0.03264215 0.7309556  0.06670206 0.02188197 0.07546765 0.07235067]\n",
      " [0.23330617 0.39054313 0.14912283 0.0241135  0.12155158 0.08136263]\n",
      " [0.03438042 0.515278   0.24600844 0.03787938 0.07962218 0.08683157]\n",
      " [0.04154665 0.22934096 0.4747564  0.0387438  0.08157634 0.13403584]\n",
      " [0.02012312 0.477037   0.29998362 0.03649629 0.04361672 0.12274334]\n",
      " [0.03011171 0.09417161 0.6394729  0.03023036 0.05005249 0.15596095]\n",
      " [0.03722121 0.4531938  0.33375755 0.01722579 0.07101941 0.08758225]\n",
      " [0.07422403 0.3243563  0.44025058 0.02062406 0.09593637 0.04460874]\n",
      " [0.03406125 0.58944494 0.14757223 0.0210804  0.10318073 0.10466047]\n",
      " [0.11084614 0.2943769  0.25923705 0.0576748  0.12248889 0.15537609]\n",
      " [0.11823145 0.4802894  0.13578542 0.02087794 0.14586848 0.09894729]\n",
      " [0.56670004 0.24683386 0.05495338 0.05908814 0.04723001 0.02519454]\n",
      " [0.08036976 0.49916002 0.13518913 0.05406544 0.10060025 0.13061537]\n",
      " [0.23429582 0.22395022 0.41968507 0.0259476  0.05719131 0.03892978]\n",
      " [0.06635466 0.4913625  0.15733032 0.08993179 0.07473588 0.12028477]\n",
      " [0.15448982 0.4105031  0.27559334 0.02919749 0.08970509 0.04051119]\n",
      " [0.07471087 0.34871617 0.20834939 0.09518208 0.06794818 0.20509335]\n",
      " [0.05710905 0.39782378 0.341515   0.05103838 0.08938884 0.06312504]\n",
      " [0.04912997 0.28586128 0.37731442 0.06784128 0.07962648 0.1402266 ]\n",
      " [0.16366975 0.30399764 0.23925366 0.07347897 0.12162498 0.09797501]\n",
      " [0.1505783  0.5127642  0.04669312 0.03712877 0.14293782 0.1098978 ]\n",
      " [0.45107338 0.29219574 0.07270031 0.05920196 0.0715957  0.05323287]\n",
      " [0.15642902 0.544645   0.03337854 0.0433273  0.12509304 0.09712715]\n",
      " [0.10539166 0.56232464 0.1332414  0.03503987 0.10895027 0.05505222]\n",
      " [0.069016   0.47814992 0.22382598 0.07275225 0.06028369 0.09597215]\n",
      " [0.05818393 0.42651698 0.34960562 0.03442534 0.08406178 0.04720634]\n",
      " [0.03729834 0.3478905  0.40600744 0.04446098 0.06513559 0.09920713]\n",
      " [0.05303059 0.34253117 0.43476206 0.04170723 0.06412093 0.06384807]\n",
      " [0.09938114 0.49822864 0.12634096 0.02315405 0.1501422  0.10275299]\n",
      " [0.25314677 0.34583873 0.09766587 0.04619143 0.11508465 0.14207256]\n",
      " [0.11585519 0.5895043  0.07405786 0.02566295 0.11878842 0.07613127]\n",
      " [0.26828077 0.47336498 0.10281938 0.03324539 0.0902003  0.03208909]\n",
      " [0.05482172 0.46343443 0.2170747  0.05545014 0.09751244 0.11170653]\n",
      " [0.05112059 0.30972266 0.3818955  0.05744601 0.06618562 0.13362966]\n",
      " [0.05169139 0.40935874 0.28594753 0.0471906  0.06616972 0.13964199]\n",
      " [0.06864574 0.42032367 0.32349125 0.02831545 0.09415925 0.06506468]\n",
      " [0.05501884 0.43459374 0.28886604 0.04242929 0.08216339 0.0969287 ]\n",
      " [0.03017646 0.4126296  0.41182938 0.02623991 0.06583077 0.05329375]\n",
      " [0.06808396 0.4580066  0.21716198 0.02708785 0.12525196 0.1044076 ]\n",
      " [0.12940599 0.32998586 0.20457715 0.03545358 0.11797176 0.18260556]\n",
      " [0.1044118  0.5735069  0.070163   0.02959407 0.11859599 0.10372824]\n",
      " [0.26885843 0.4864603  0.04656358 0.03030451 0.08400362 0.08380949]\n",
      " [0.05506011 0.44134864 0.25400746 0.05367939 0.07968774 0.11621659]\n",
      " [0.04350975 0.42718992 0.32082567 0.0369438  0.09103714 0.08049366]\n",
      " [0.02942141 0.39256936 0.3340285  0.055068   0.04855662 0.14035618]\n",
      " [0.03148818 0.29848838 0.37405533 0.04351289 0.06336033 0.18909492]\n",
      " [0.0606555  0.42187363 0.28457752 0.02960304 0.07108229 0.13220802]\n",
      " [0.04890113 0.54772407 0.2492362  0.02082643 0.08887602 0.04443617]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(y_test)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 6, 6, 1, 1, 3, 6, 5, 1, 6, 2, 3, 4, 6, 1, 4, 1, 6, 6, 1, 4, 6, 6, 2, 5, 6, 6, 4, 5, 1, 6, 3, 5, 1, 1, 1, 3, 6, 6, 5, 2, 1, 1, 4, 1, 1, 1, 2, 4, 3, 6, 1, 2, 6, 1, 1, 5, 6, 6, 4, 4, 6, 6, 5, 4, 6, 2, 4, 2, 1, 3, 4, 5, 3, 6, 3, 2, 2, 2, 4, 5, 2, 2, 1, 3, 3, 6, 5, 5, 6, 6, 1, 2, 3, 3, 1, 5, 6, 6, 1, 4, 3, 6, 3, 3, 2, 6, 1, 2, 2, 6, 1, 5, 3, 1, 2, 1, 1, 6, 3, 5, 6, 2, 2, 4, 2, 6, 5, 3, 1, 6, 4, 4, 3, 2, 1, 2, 6, 3, 5, 1, 1, 6, 5, 1, 2, 3, 2, 5]\n",
      "[6, 1, 6, 1, 1, 1, 1, 1, 2, 3, 6, 6, 6, 1, 2, 1, 2, 1, 6, 1, 2, 1, 2, 1, 2, 1, 6, 1, 2, 1, 6, 1, 2, 1, 2, 1, 6, 1, 2, 3, 6, 1, 2, 1, 2, 2, 2, 3, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 2, 3, 2, 2, 2, 1, 2, 3, 2, 3, 2, 3, 2, 2, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 2, 1, 2, 3, 2, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_to_labels(y_labels, arr):\n",
    "   \n",
    "    # Convert predictions to class indices\n",
    "    classes = np.argmax(arr, axis=1)\n",
    "    \n",
    "    labels =   [y_labels[i] for i in classes]\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "predictions_labels = convert_to_labels(y_labels , predictions)\n",
    "y_test_labels = convert_to_labels(y_labels, y_test)\n",
    "\n",
    "print(y_test_labels)\n",
    "print(predictions_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 1, 3, 5, 6, 3, 6, 4, 6, 1, 6, 2, 6, 4, 1, 3, 1, 1, 6, 5, 1, 4, 1, 2, 3, 1, 6, 1, 6, 4, 6, 5, 6, 4, 1, 4, 3, 3, 2, 4, 2, 1, 3, 5, 6, 1, 3, 1, 6, 1, 3, 3, 2, 1, 2, 1, 3, 2, 1, 3, 6, 2, 2, 5, 1, 4, 3, 1, 6, 5, 1, 5, 2, 2]\n",
      "[6, 6, 1, 1, 2, 6, 6, 2, 2, 6, 2, 2, 2, 6, 2, 6, 2, 2, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "def make_pair(arr):\n",
    "    if len(arr) % 2 == 0:\n",
    "        arr = arr\n",
    "    else:\n",
    "        arr = arr[1:] \n",
    "    return arr\n",
    "\n",
    "pr = make_pair(predictions_labels)\n",
    "real = make_pair(y_test_labels)\n",
    "\n",
    "\n",
    "pr_cj = []\n",
    "real_cj = []\n",
    "\n",
    "for i in range(len(pr)):\n",
    "    if i % 2 == 0:\n",
    "        pr_cj.append(pr[i])\n",
    "        real_cj.append(real[i])\n",
    "\n",
    "print(real_cj)\n",
    "print(pr_cj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc =  0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_accuracy(arr1, arr2):\n",
    "    gr1 = [2,3, 1]\n",
    "    gr2 = [4,5,6]\n",
    "    if len(arr1) != len(arr2):\n",
    "        raise ValueError(\"Arrays must have the same length\")\n",
    "    \n",
    "    arr1 = list(map(int, arr1))\n",
    "    arr2 = list(map(int, arr2))\n",
    "    \n",
    "    correct_predictions = sum((a in gr1 and b in  gr1) or (a in gr2 and b in  gr2) for a, b in zip(arr1, arr2))\n",
    "    accuracy = correct_predictions / len(arr1)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "print(\"acc = \", calculate_accuracy(y_test_labels, predictions_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
