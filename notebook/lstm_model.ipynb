{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 13:18:22.196532: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-18 13:18:22.240918: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-18 13:18:22.242270: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-18 13:18:23.004668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2, 381), (2, 381))\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 760 entries, 0 to 759\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   NAME                 760 non-null    object \n",
      " 1   date                 760 non-null    int64  \n",
      " 2   color_and_value      760 non-null    object \n",
      " 3   name_code            760 non-null    int64  \n",
      " 4   day_of_month         760 non-null    int32  \n",
      " 5   day_of_week          760 non-null    int32  \n",
      " 6   date_code            760 non-null    int64  \n",
      " 7   day_of_year          760 non-null    int64  \n",
      " 8   value                760 non-null    float64\n",
      " 9   color                760 non-null    object \n",
      " 10  extra                760 non-null    float64\n",
      " 11  color_code           760 non-null    int64  \n",
      " 12  next_color_code      758 non-null    float64\n",
      " 13  previous_color_code  758 non-null    float64\n",
      " 14  color_binary         760 non-null    int64  \n",
      " 15  next_color_binary    758 non-null    float64\n",
      " 16  color_group          760 non-null    int64  \n",
      " 17  next_color_group     758 non-null    float64\n",
      "dtypes: float64(6), int32(2), int64(7), object(3)\n",
      "memory usage: 101.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>date</th>\n",
       "      <th>color_and_value</th>\n",
       "      <th>name_code</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>date_code</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>value</th>\n",
       "      <th>color</th>\n",
       "      <th>extra</th>\n",
       "      <th>color_code</th>\n",
       "      <th>next_color_code</th>\n",
       "      <th>previous_color_code</th>\n",
       "      <th>color_binary</th>\n",
       "      <th>next_color_binary</th>\n",
       "      <th>color_group</th>\n",
       "      <th>next_color_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CJ1</td>\n",
       "      <td>1733702400000000000</td>\n",
       "      <td>0.42857 | FF0000 | 184733</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "      <td>0.42857</td>\n",
       "      <td>FF0000</td>\n",
       "      <td>184733.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CJ2</td>\n",
       "      <td>1733702400000000000</td>\n",
       "      <td>0.0 | FF9900 | 1224919</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>FF9900</td>\n",
       "      <td>1224919.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CJ1</td>\n",
       "      <td>1733961600000000000</td>\n",
       "      <td>0.28571 | D5A6BD | 167139</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>0.28571</td>\n",
       "      <td>D5A6BD</td>\n",
       "      <td>167139.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CJ2</td>\n",
       "      <td>1733961600000000000</td>\n",
       "      <td>-0.1429 | 00FF00 | 1091707</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>-0.14290</td>\n",
       "      <td>00FF00</td>\n",
       "      <td>1091707.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CJ1</td>\n",
       "      <td>1734048000000000000</td>\n",
       "      <td>0.28571 | FF9900 | 138497</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>348</td>\n",
       "      <td>0.28571</td>\n",
       "      <td>FF9900</td>\n",
       "      <td>138497.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>CJ2</td>\n",
       "      <td>1716940800100000000</td>\n",
       "      <td>11.7143 | FFFF00 | 1117856</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>150</td>\n",
       "      <td>11.71430</td>\n",
       "      <td>FFFF00</td>\n",
       "      <td>1117856.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>CJ1</td>\n",
       "      <td>1717027200100000000</td>\n",
       "      <td>15.5714 | 00FF00 | 61845</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>378</td>\n",
       "      <td>151</td>\n",
       "      <td>15.57140</td>\n",
       "      <td>00FF00</td>\n",
       "      <td>61845.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>CJ2</td>\n",
       "      <td>1717027200100000000</td>\n",
       "      <td>11.5714 | FF9900 | 1280565</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>378</td>\n",
       "      <td>151</td>\n",
       "      <td>11.57140</td>\n",
       "      <td>FF9900</td>\n",
       "      <td>1280565.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>CJ1</td>\n",
       "      <td>1717113600100000000</td>\n",
       "      <td>15.5714 | FFFF00 | 58560</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>379</td>\n",
       "      <td>152</td>\n",
       "      <td>15.57140</td>\n",
       "      <td>FFFF00</td>\n",
       "      <td>58560.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>CJ2</td>\n",
       "      <td>1717113600100000000</td>\n",
       "      <td>11.4286 | 00FF00 | 1296267</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>379</td>\n",
       "      <td>152</td>\n",
       "      <td>11.42860</td>\n",
       "      <td>00FF00</td>\n",
       "      <td>1296267.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    NAME                 date             color_and_value  name_code  \\\n",
       "0    CJ1  1733702400000000000   0.42857 | FF0000 | 184733          1   \n",
       "1    CJ2  1733702400000000000      0.0 | FF9900 | 1224919          2   \n",
       "2    CJ1  1733961600000000000   0.28571 | D5A6BD | 167139          1   \n",
       "3    CJ2  1733961600000000000  -0.1429 | 00FF00 | 1091707          2   \n",
       "4    CJ1  1734048000000000000   0.28571 | FF9900 | 138497          1   \n",
       "..   ...                  ...                         ...        ...   \n",
       "755  CJ2  1716940800100000000  11.7143 | FFFF00 | 1117856          2   \n",
       "756  CJ1  1717027200100000000    15.5714 | 00FF00 | 61845          1   \n",
       "757  CJ2  1717027200100000000  11.5714 | FF9900 | 1280565          2   \n",
       "758  CJ1  1717113600100000000    15.5714 | FFFF00 | 58560          1   \n",
       "759  CJ2  1717113600100000000  11.4286 | 00FF00 | 1296267          2   \n",
       "\n",
       "     day_of_month  day_of_week  date_code  day_of_year     value   color  \\\n",
       "0               9            0          0          344   0.42857  FF0000   \n",
       "1               9            0          0          344   0.00000  FF9900   \n",
       "2              12            3          1          347   0.28571  D5A6BD   \n",
       "3              12            3          1          347  -0.14290  00FF00   \n",
       "4              13            4          2          348   0.28571  FF9900   \n",
       "..            ...          ...        ...          ...       ...     ...   \n",
       "755            29            2        377          150  11.71430  FFFF00   \n",
       "756            30            3        378          151  15.57140  00FF00   \n",
       "757            30            3        378          151  11.57140  FF9900   \n",
       "758            31            4        379          152  15.57140  FFFF00   \n",
       "759            31            4        379          152  11.42860  00FF00   \n",
       "\n",
       "         extra  color_code  next_color_code  previous_color_code  \\\n",
       "0     184733.0           0              2.0                  NaN   \n",
       "1    1224919.0           1              3.0                  NaN   \n",
       "2     167139.0           2              1.0                  0.0   \n",
       "3    1091707.0           3              1.0                  1.0   \n",
       "4     138497.0           1              0.0                  2.0   \n",
       "..         ...         ...              ...                  ...   \n",
       "755  1117856.0           4              1.0                  0.0   \n",
       "756    61845.0           3              4.0                  3.0   \n",
       "757  1280565.0           1              3.0                  4.0   \n",
       "758    58560.0           4              NaN                  3.0   \n",
       "759  1296267.0           3              NaN                  1.0   \n",
       "\n",
       "     color_binary  next_color_binary  color_group  next_color_group  \n",
       "0               1                0.0            1               6.0  \n",
       "1               0                1.0            5               2.0  \n",
       "2               0                0.0            6               5.0  \n",
       "3               1                0.0            2               5.0  \n",
       "4               0                1.0            5               1.0  \n",
       "..            ...                ...          ...               ...  \n",
       "755             1                0.0            3               5.0  \n",
       "756             1                1.0            2               3.0  \n",
       "757             0                1.0            5               2.0  \n",
       "758             1                NaN            3               NaN  \n",
       "759             1                NaN            2               NaN  \n",
       "\n",
       "[760 rows x 18 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Pandas library\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.tensorflow_model import TensorFlowModel\n",
    "\n",
    "model = TensorFlowModel()\n",
    "path = \"../test_data/new_data.xlsx\"\n",
    "\n",
    "coded_df = model.process_excel(path)\n",
    "\n",
    "\n",
    "print(coded_df.info())\n",
    "coded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_code</th>\n",
       "      <th>name_code</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>color_code</th>\n",
       "      <th>value</th>\n",
       "      <th>color_group</th>\n",
       "      <th>extra</th>\n",
       "      <th>next_color_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.42857</td>\n",
       "      <td>1</td>\n",
       "      <td>184733.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>344</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5</td>\n",
       "      <td>1224919.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.28571</td>\n",
       "      <td>6</td>\n",
       "      <td>167139.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>347</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.14290</td>\n",
       "      <td>2</td>\n",
       "      <td>1091707.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>348</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.28571</td>\n",
       "      <td>5</td>\n",
       "      <td>138497.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>377</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11.71430</td>\n",
       "      <td>3</td>\n",
       "      <td>1117856.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>378</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15.57140</td>\n",
       "      <td>2</td>\n",
       "      <td>61845.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>378</td>\n",
       "      <td>2</td>\n",
       "      <td>151</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11.57140</td>\n",
       "      <td>5</td>\n",
       "      <td>1280565.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>379</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>15.57140</td>\n",
       "      <td>3</td>\n",
       "      <td>58560.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>379</td>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>11.42860</td>\n",
       "      <td>2</td>\n",
       "      <td>1296267.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_code  name_code  day_of_year  day_of_month  day_of_week  color_code  \\\n",
       "0            0          1          344             9            0           0   \n",
       "1            0          2          344             9            0           1   \n",
       "2            1          1          347            12            3           2   \n",
       "3            1          2          347            12            3           3   \n",
       "4            2          1          348            13            4           1   \n",
       "..         ...        ...          ...           ...          ...         ...   \n",
       "755        377          2          150            29            2           4   \n",
       "756        378          1          151            30            3           3   \n",
       "757        378          2          151            30            3           1   \n",
       "758        379          1          152            31            4           4   \n",
       "759        379          2          152            31            4           3   \n",
       "\n",
       "        value  color_group      extra  next_color_group  \n",
       "0     0.42857            1   184733.0               6.0  \n",
       "1     0.00000            5  1224919.0               2.0  \n",
       "2     0.28571            6   167139.0               5.0  \n",
       "3    -0.14290            2  1091707.0               5.0  \n",
       "4     0.28571            5   138497.0               1.0  \n",
       "..        ...          ...        ...               ...  \n",
       "755  11.71430            3  1117856.0               5.0  \n",
       "756  15.57140            2    61845.0               3.0  \n",
       "757  11.57140            5  1280565.0               2.0  \n",
       "758  15.57140            3    58560.0               NaN  \n",
       "759  11.42860            2  1296267.0               NaN  \n",
       "\n",
       "[760 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coded_df[[\"date_code\"  ,'name_code' , 'day_of_year', 'day_of_month', 'day_of_week' ,\"color_code\" , 'value' , 'color_group','extra',  'next_color_group' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(760, 8)\n",
      "(760, 6)\n",
      "     date_code  name_code  day_of_year  day_of_month  day_of_week  \\\n",
      "755        377          2          150            29            2   \n",
      "756        378          1          151            30            3   \n",
      "757        378          2          151            30            3   \n",
      "758        379          1          152            31            4   \n",
      "759        379          2          152            31            4   \n",
      "\n",
      "     color_group      extra    value  \n",
      "755            3  1117856.0  11.7143  \n",
      "756            2    61845.0  15.5714  \n",
      "757            5  1280565.0  11.5714  \n",
      "758            3    58560.0  15.5714  \n",
      "759            2  1296267.0  11.4286  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# coded_df = coded_df.dropna(axis=0)\n",
    "\n",
    "\n",
    "X = coded_df[[\"date_code\"  ,'name_code' , 'day_of_year', 'day_of_month', 'day_of_week' ,\"color_group\" ,'extra', 'value']]\n",
    "\n",
    "\n",
    "y = pd.get_dummies(coded_df['color_group']).astype(int)  # One-hot encode the target\n",
    "\n",
    "y_labels = y.columns\n",
    "\n",
    "y = y.values\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "print(X[len(X) - 5:len(X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(760, 8)\n",
      "(760, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "print(y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(740, 20, 8)\n",
      "(740, 6)\n",
      "(1, 20, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_sequences(X,y, timesteps):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(X) - timesteps):\n",
    "        sequences.append(X[i:i + timesteps])\n",
    "        labels.append(y[i + timesteps])\n",
    "    \n",
    "    X_last = [X[len(X) - timesteps:len(X)]]\n",
    "    \n",
    "    return np.array(sequences), np.array(labels), np.array(X_last)\n",
    "\n",
    "\n",
    "timesteps =20\n",
    "\n",
    "X , y, X_last = create_sequences(X,y, timesteps)\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(X_last.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(740, 20, 8)\n",
      "(740, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,shuffle=False)\n",
    "\n",
    "# Normalize the feature data (optional but recommended for neural networks)\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization ,Flatten\n",
    "# Define the input shape for LSTM\n",
    "\n",
    "input_shape = (timesteps, X.shape[2])\n",
    "\n",
    "model = Sequential([\n",
    "    # Flatten the input before feeding into Dense layers\n",
    "    Flatten(input_shape=input_shape),\n",
    "\n",
    "    # First dense layer with Batch Normalization and Dropout\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),  # Dropout for regularization\n",
    "\n",
    "    # Second dense layer with Batch Normalization and Dropout\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),  # Dropout for regularization\n",
    "\n",
    "    # Third dense layer with Batch Normalization and Dropout\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),  # Dropout for regularization\n",
    "\n",
    "    # Fourth dense layer with Batch Normalization and Dropout\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),  # Dropout for regularization\n",
    "\n",
    "    # Output layer\n",
    "    Dense(y_test.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "60/60 [==============================] - 2s 7ms/step - loss: 2.6027 - accuracy: 0.1436\n",
      "Epoch 2/60\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 2.2898 - accuracy: 0.1875\n",
      "Epoch 3/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 2.0597 - accuracy: 0.2111\n",
      "Epoch 4/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 2.0618 - accuracy: 0.2162\n",
      "Epoch 5/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.9579 - accuracy: 0.2128\n",
      "Epoch 6/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.9457 - accuracy: 0.2348\n",
      "Epoch 7/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.9127 - accuracy: 0.2230\n",
      "Epoch 8/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.8641 - accuracy: 0.2399\n",
      "Epoch 9/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.8106 - accuracy: 0.2601\n",
      "Epoch 10/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.8498 - accuracy: 0.1824\n",
      "Epoch 11/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7706 - accuracy: 0.2382\n",
      "Epoch 12/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7742 - accuracy: 0.2855\n",
      "Epoch 13/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7400 - accuracy: 0.2770\n",
      "Epoch 14/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7127 - accuracy: 0.2838\n",
      "Epoch 15/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7391 - accuracy: 0.2922\n",
      "Epoch 16/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7039 - accuracy: 0.3091\n",
      "Epoch 17/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7226 - accuracy: 0.2753\n",
      "Epoch 18/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7102 - accuracy: 0.2889\n",
      "Epoch 19/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6929 - accuracy: 0.3057\n",
      "Epoch 20/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6745 - accuracy: 0.3041\n",
      "Epoch 21/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7029 - accuracy: 0.3125\n",
      "Epoch 22/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7138 - accuracy: 0.2905\n",
      "Epoch 23/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6854 - accuracy: 0.2973\n",
      "Epoch 24/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7008 - accuracy: 0.2821\n",
      "Epoch 25/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.7096 - accuracy: 0.2736\n",
      "Epoch 26/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6672 - accuracy: 0.3311\n",
      "Epoch 27/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6762 - accuracy: 0.3091\n",
      "Epoch 28/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6483 - accuracy: 0.3193\n",
      "Epoch 29/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6664 - accuracy: 0.3074\n",
      "Epoch 30/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6554 - accuracy: 0.3142\n",
      "Epoch 31/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6628 - accuracy: 0.3108\n",
      "Epoch 32/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6553 - accuracy: 0.3091\n",
      "Epoch 33/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6688 - accuracy: 0.3176\n",
      "Epoch 34/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6239 - accuracy: 0.3395\n",
      "Epoch 35/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6366 - accuracy: 0.3395\n",
      "Epoch 36/60\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 1.6332 - accuracy: 0.3142\n",
      "Epoch 37/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6538 - accuracy: 0.3294\n",
      "Epoch 38/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6738 - accuracy: 0.2787\n",
      "Epoch 39/60\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 1.6642 - accuracy: 0.2990\n",
      "Epoch 40/60\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 1.6443 - accuracy: 0.3074\n",
      "Epoch 41/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6085 - accuracy: 0.3666\n",
      "Epoch 42/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6429 - accuracy: 0.3125\n",
      "Epoch 43/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6506 - accuracy: 0.3108\n",
      "Epoch 44/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6308 - accuracy: 0.3176\n",
      "Epoch 45/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6233 - accuracy: 0.3581\n",
      "Epoch 46/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6312 - accuracy: 0.3243\n",
      "Epoch 47/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6283 - accuracy: 0.3108\n",
      "Epoch 48/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6140 - accuracy: 0.3429\n",
      "Epoch 49/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6364 - accuracy: 0.3311\n",
      "Epoch 50/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5992 - accuracy: 0.3699\n",
      "Epoch 51/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6035 - accuracy: 0.3514\n",
      "Epoch 52/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5906 - accuracy: 0.3615\n",
      "Epoch 53/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5843 - accuracy: 0.3598\n",
      "Epoch 54/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5768 - accuracy: 0.3514\n",
      "Epoch 55/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5749 - accuracy: 0.3851\n",
      "Epoch 56/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.6065 - accuracy: 0.3463\n",
      "Epoch 57/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5936 - accuracy: 0.3497\n",
      "Epoch 58/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5828 - accuracy: 0.3412\n",
      "Epoch 59/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5767 - accuracy: 0.3463\n",
      "Epoch 60/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.5775 - accuracy: 0.3834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb304e6e580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=60, batch_size=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 1.8060 - accuracy: 0.2297\n",
      "Test Accuracy: 0.22972972691059113\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "[[1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0]]\n",
      "[[0.40636513 0.21965429 0.07814255 0.09642958 0.09611956 0.10328877]\n",
      " [0.31321996 0.16881941 0.09331893 0.07564951 0.10814096 0.24085121]\n",
      " [0.32500032 0.24661651 0.09484493 0.09937122 0.097061   0.13710591]\n",
      " [0.25590807 0.09743811 0.2930627  0.05207508 0.13584603 0.16567   ]\n",
      " [0.26595357 0.29728094 0.12882    0.11110753 0.08264552 0.1141924 ]\n",
      " [0.2035707  0.11252117 0.29692605 0.07040852 0.14474106 0.17183252]\n",
      " [0.2366844  0.26985788 0.14956026 0.10292495 0.09127363 0.14969882]\n",
      " [0.17437801 0.14640458 0.26579967 0.07768074 0.1248761  0.21086085]\n",
      " [0.34742805 0.22099054 0.09991322 0.09624772 0.09891652 0.1365039 ]\n",
      " [0.20107007 0.21651216 0.10404602 0.08614005 0.15349293 0.23873867]\n",
      " [0.36331165 0.23810591 0.08451886 0.10580165 0.09785553 0.11040641]\n",
      " [0.28105736 0.14953238 0.10429356 0.07962662 0.12579967 0.25969046]\n",
      " [0.29383364 0.25085256 0.11878431 0.10182803 0.09746923 0.13723218]\n",
      " [0.21312018 0.07991748 0.29808193 0.05557172 0.16357878 0.1897299 ]\n",
      " [0.22277573 0.3066682  0.14912634 0.10001694 0.08885413 0.13255867]\n",
      " [0.21748032 0.07704518 0.3720193  0.05206633 0.115592   0.16579683]\n",
      " [0.25110593 0.30249658 0.14367945 0.09875425 0.08749592 0.11646792]\n",
      " [0.22590403 0.19054003 0.1789085  0.08088989 0.11974813 0.20400944]\n",
      " [0.21381924 0.29180977 0.15625511 0.09505062 0.09304164 0.15002358]\n",
      " [0.25098094 0.13183218 0.24075705 0.05374693 0.11333343 0.20934942]\n",
      " [0.33805066 0.24431054 0.12267832 0.07831749 0.10640691 0.11023612]\n",
      " [0.36024255 0.14469343 0.18036507 0.0537134  0.09533224 0.16565338]\n",
      " [0.25659537 0.25795862 0.14595522 0.08781259 0.09786604 0.1538121 ]\n",
      " [0.29596463 0.04557688 0.46702698 0.02639267 0.07223115 0.0928076 ]\n",
      " [0.34850097 0.2352698  0.13880509 0.09026572 0.08789124 0.09926704]\n",
      " [0.34675032 0.07342643 0.3883534  0.02486239 0.08019288 0.08641457]\n",
      " [0.2714181  0.22218047 0.15136467 0.07861332 0.10410088 0.17232245]\n",
      " [0.29493222 0.11107765 0.37439537 0.04578521 0.06058228 0.11322724]\n",
      " [0.41987348 0.15590353 0.17463537 0.05942107 0.09099486 0.09917178]\n",
      " [0.31672654 0.1147626  0.31240997 0.05509469 0.07235453 0.12865175]\n",
      " [0.47232425 0.13771711 0.09399902 0.05949609 0.10513355 0.13132992]\n",
      " [0.3257126  0.16383925 0.11653715 0.0568809  0.09181681 0.2452133 ]\n",
      " [0.305295   0.2393154  0.10817904 0.09810054 0.09848969 0.15062031]\n",
      " [0.26815692 0.0990149  0.317128   0.06002485 0.10120004 0.15447529]\n",
      " [0.27834803 0.23832846 0.13715523 0.09599411 0.0852856  0.1648885 ]\n",
      " [0.21230422 0.09601077 0.39206994 0.07070941 0.10191123 0.12699437]\n",
      " [0.2773103  0.25077957 0.12641512 0.10451692 0.09047395 0.15050407]\n",
      " [0.15602441 0.2142363  0.20830444 0.10128569 0.12212712 0.19802204]\n",
      " [0.3197447  0.22833446 0.10456771 0.09238487 0.09903876 0.15592949]\n",
      " [0.17694224 0.24638775 0.14986867 0.09070961 0.12857565 0.20751612]\n",
      " [0.4179087  0.20577703 0.08131924 0.07585729 0.10120078 0.11793699]\n",
      " [0.21440849 0.24238402 0.14584771 0.0948681  0.10880862 0.19368312]\n",
      " [0.29524156 0.2476275  0.11613235 0.08496164 0.10240316 0.15363379]\n",
      " [0.16549174 0.153587   0.25801075 0.09802486 0.13584206 0.18904352]\n",
      " [0.21447404 0.289388   0.14613369 0.09574638 0.0954549  0.15880294]\n",
      " [0.18633538 0.11545264 0.4026162  0.08001887 0.08679742 0.1287796 ]\n",
      " [0.21729797 0.28733417 0.14853647 0.10297686 0.0919915  0.15186308]\n",
      " [0.17144716 0.2520417  0.21560027 0.1105336  0.08925398 0.1611234 ]\n",
      " [0.22232322 0.28037256 0.15022087 0.0920258  0.09349804 0.16155936]\n",
      " [0.16233943 0.2464116  0.15929319 0.09943616 0.12067951 0.21184015]\n",
      " [0.2951483  0.25845975 0.13226706 0.07669646 0.09744023 0.13998814]\n",
      " [0.23637022 0.18567319 0.22816151 0.08242984 0.0917917  0.17557345]\n",
      " [0.23631366 0.2887989  0.13944344 0.0849167  0.10046174 0.15006551]\n",
      " [0.18165138 0.23514657 0.1886985  0.09717131 0.1237235  0.17360875]\n",
      " [0.19938329 0.30339506 0.162249   0.09646612 0.09101351 0.1474929 ]\n",
      " [0.19525468 0.15003328 0.35355482 0.0666606  0.09484352 0.13965316]\n",
      " [0.21962357 0.29666486 0.16818465 0.08561453 0.09064593 0.13926642]\n",
      " [0.17054318 0.24470834 0.21001695 0.10080113 0.10058376 0.17334655]\n",
      " [0.20393799 0.30766493 0.15898778 0.07934418 0.09834447 0.15172057]\n",
      " [0.20116767 0.21207018 0.23914646 0.09290548 0.08888586 0.16582434]\n",
      " [0.3237571  0.25661588 0.13112842 0.06916439 0.09638234 0.12295184]\n",
      " [0.25391132 0.2024073  0.26924717 0.07187071 0.07259201 0.12997156]\n",
      " [0.2544327  0.28224763 0.15025844 0.07847179 0.0933471  0.14124241]\n",
      " [0.23995829 0.16473888 0.34025943 0.06278688 0.07010361 0.12215291]\n",
      " [0.29006657 0.26714078 0.14899002 0.07834761 0.09796941 0.11748547]\n",
      " [0.27580512 0.15743425 0.36555037 0.06695365 0.04778722 0.0864694 ]\n",
      " [0.29638252 0.22029656 0.15507145 0.056589   0.10964745 0.16201307]\n",
      " [0.24117623 0.1998952  0.3037804  0.0938427  0.05324129 0.10806413]\n",
      " [0.4027677  0.18492892 0.13458991 0.0677461  0.09812796 0.11183959]\n",
      " [0.34440926 0.16403367 0.25618064 0.07273706 0.04801621 0.11462311]\n",
      " [0.3409014  0.2002434  0.12301603 0.07671355 0.09372114 0.16540435]\n",
      " [0.23799326 0.19205159 0.25435492 0.09464169 0.07253776 0.14842081]\n",
      " [0.2641269  0.25964743 0.13400263 0.0968881  0.09062668 0.15470819]\n",
      " [0.20295814 0.17242245 0.33706194 0.09232952 0.06411404 0.13111399]\n",
      " [0.27489227 0.2531052  0.13396797 0.08542675 0.08831125 0.16429661]\n",
      " [0.15804705 0.24720718 0.22106133 0.10880895 0.09269756 0.17217788]\n",
      " [0.29771507 0.25041163 0.12329676 0.07656068 0.09215068 0.15986513]\n",
      " [0.17323022 0.27967262 0.14622146 0.10042632 0.10905548 0.19139393]\n",
      " [0.3566893  0.21519643 0.10544826 0.07110342 0.10353339 0.14802909]\n",
      " [0.19381541 0.26220772 0.18065737 0.09777558 0.08934197 0.17620209]\n",
      " [0.27107    0.24962486 0.1052205  0.08327259 0.1074895  0.18332264]\n",
      " [0.19449401 0.19750728 0.23542425 0.0946703  0.10715399 0.17075014]\n",
      " [0.24841501 0.28724813 0.14038385 0.09217379 0.08689863 0.14488056]\n",
      " [0.16881676 0.15044065 0.335688   0.08838939 0.1056098  0.15105534]\n",
      " [0.22042808 0.28416896 0.1540915  0.08445383 0.09280007 0.16405758]\n",
      " [0.15242599 0.17601223 0.30039847 0.09454882 0.09998966 0.17662495]\n",
      " [0.23499556 0.2836831  0.13742414 0.08205301 0.10009918 0.16174509]\n",
      " [0.16958785 0.25685984 0.16460171 0.09404491 0.10515514 0.20975061]\n",
      " [0.302444   0.25298548 0.1210915  0.06924748 0.10757285 0.14665867]\n",
      " [0.21684554 0.2741356  0.15800017 0.09162793 0.0851748  0.17421593]\n",
      " [0.24329679 0.27623764 0.13760546 0.0736798  0.10466421 0.16451606]\n",
      " [0.17703108 0.16385786 0.28646064 0.08741766 0.11984662 0.16538616]\n",
      " [0.2199364  0.29378098 0.16515663 0.08621809 0.09114781 0.14376006]\n",
      " [0.16988625 0.15212485 0.3266577  0.07504013 0.12314912 0.15314199]\n",
      " [0.19471683 0.3026399  0.1653337  0.08549699 0.09388024 0.15793231]\n",
      " [0.18116191 0.19183213 0.28673637 0.0896749  0.08535182 0.16524282]\n",
      " [0.26061073 0.27579045 0.14710723 0.0826901  0.09355534 0.14024618]\n",
      " [0.17874879 0.2665152  0.15449692 0.09446615 0.11090856 0.19486445]\n",
      " [0.26793653 0.27795595 0.13801326 0.07222196 0.09990637 0.14396583]\n",
      " [0.22464933 0.19692312 0.21928546 0.08602284 0.0899473  0.18317185]\n",
      " [0.25944155 0.28368706 0.15569735 0.07694651 0.09574176 0.12848575]\n",
      " [0.18237019 0.1587774  0.28509662 0.08080126 0.12985139 0.16310312]\n",
      " [0.19499995 0.3017171  0.17593184 0.08475494 0.09227668 0.15031955]\n",
      " [0.18439238 0.14821415 0.33729127 0.06297252 0.10855387 0.1585758 ]\n",
      " [0.23572388 0.3019661  0.16186048 0.08187169 0.09010982 0.12846798]\n",
      " [0.19402519 0.23530434 0.28504717 0.08555505 0.06551941 0.13454895]\n",
      " [0.26796535 0.2488562  0.16528063 0.05445505 0.10358015 0.15986258]\n",
      " [0.2048954  0.2387712  0.24962834 0.09163396 0.06697939 0.14809161]\n",
      " [0.38959706 0.20665413 0.12143695 0.04707235 0.12593685 0.10930266]\n",
      " [0.35727012 0.16456726 0.25188255 0.06210316 0.05746447 0.1067124 ]\n",
      " [0.3146711  0.21574184 0.14015146 0.06998608 0.10364448 0.15580502]\n",
      " [0.2573565  0.08436155 0.45041788 0.05952805 0.05257016 0.09576586]\n",
      " [0.29412636 0.22526905 0.15582684 0.08620483 0.09271922 0.14585368]\n",
      " [0.23586093 0.09421126 0.4592554  0.07666905 0.05186838 0.08213498]\n",
      " [0.28328475 0.20478727 0.15214689 0.08116664 0.09575032 0.18286411]\n",
      " [0.17724863 0.22992538 0.2677205  0.11030886 0.06637421 0.1484223 ]\n",
      " [0.29445004 0.23320937 0.13563463 0.07484283 0.0946991  0.16716397]\n",
      " [0.19114168 0.25874072 0.18730788 0.10635851 0.08088624 0.17556489]\n",
      " [0.33198398 0.21109125 0.10529875 0.07701537 0.10978931 0.1648214 ]\n",
      " [0.22008204 0.215939   0.22156739 0.09524783 0.07076091 0.17640273]\n",
      " [0.29124278 0.24152145 0.11848985 0.07464723 0.09832626 0.17577232]\n",
      " [0.20085719 0.20103304 0.23086035 0.09837798 0.09423763 0.17463389]\n",
      " [0.24001825 0.2726289  0.14372568 0.08487171 0.09040958 0.16834594]\n",
      " [0.17199849 0.19191417 0.26646787 0.09251349 0.09691298 0.18019295]\n",
      " [0.23155141 0.27326065 0.16151541 0.0833038  0.0894758  0.16089295]\n",
      " [0.1688696  0.22237995 0.23730403 0.11065954 0.08641385 0.17437309]\n",
      " [0.23376878 0.2609469  0.14583251 0.07547567 0.09636328 0.18761283]\n",
      " [0.21983737 0.23963106 0.1721808  0.10404979 0.08864765 0.17565337]\n",
      " [0.33073443 0.22645496 0.1162121  0.06915323 0.10055086 0.1568944 ]\n",
      " [0.23652513 0.22591923 0.20589441 0.09713003 0.07180675 0.16272444]\n",
      " [0.28378108 0.25188148 0.12683804 0.07574211 0.091072   0.17068511]\n",
      " [0.17946796 0.22097608 0.21396467 0.10869157 0.0915425  0.1853573 ]\n",
      " [0.2144847  0.27507043 0.16373602 0.09134071 0.08840637 0.16696174]\n",
      " [0.18456298 0.21503241 0.253737   0.10190855 0.08390526 0.16085385]\n",
      " [0.22690444 0.26544175 0.17295322 0.08736197 0.08662237 0.16071628]\n",
      " [0.19302829 0.24954356 0.22003773 0.10006004 0.08019082 0.15713948]\n",
      " [0.26799053 0.24915852 0.1405648  0.08181181 0.09251078 0.1679636 ]\n",
      " [0.1897319  0.24414037 0.18511751 0.10821052 0.08873    0.18406977]\n",
      " [0.33311602 0.22582965 0.12102115 0.07553866 0.09812306 0.1463715 ]\n",
      " [0.2534061  0.20928352 0.19952185 0.10191433 0.06535702 0.17051719]\n",
      " [0.25118777 0.2606159  0.1567774  0.08171938 0.08972207 0.1599775 ]\n",
      " [0.20808047 0.22558247 0.21208084 0.09687512 0.08466923 0.1727119 ]\n",
      " [0.22536191 0.26318172 0.18577297 0.08284696 0.08711351 0.15572296]\n",
      " [0.1797531  0.23445594 0.22678262 0.10418554 0.08859736 0.16622542]\n",
      " [0.2060457  0.28341597 0.17145528 0.08042755 0.09054732 0.16810818]\n",
      " [0.2022965  0.2518976  0.21080364 0.10013971 0.07640864 0.15845399]\n",
      " [0.23113407 0.27582812 0.16480964 0.06660815 0.10230767 0.15931247]\n",
      " [0.19790047 0.24563612 0.1917854  0.09669125 0.08693585 0.18105091]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(y_test)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all prediction\n",
      "[1, 1, 3, 6, 5, 1, 6, 2, 3, 4, 6, 1, 4, 1, 6, 6, 1, 4, 6, 6, 2, 5, 6, 6, 4, 5, 1, 6, 3, 5, 1, 1, 1, 3, 6, 6, 5, 2, 1, 1, 4, 1, 1, 1, 2, 4, 3, 6, 1, 2, 6, 1, 1, 5, 6, 6, 4, 4, 6, 6, 5, 4, 6, 2, 4, 2, 1, 3, 4, 5, 3, 6, 3, 2, 2, 2, 4, 5, 2, 2, 1, 3, 3, 6, 5, 5, 6, 6, 1, 2, 3, 3, 1, 5, 6, 6, 1, 4, 3, 6, 3, 3, 2, 6, 1, 2, 2, 6, 1, 5, 3, 1, 2, 1, 1, 6, 3, 5, 6, 2, 2, 4, 2, 6, 5, 3, 1, 6, 4, 4, 3, 2, 1, 2, 6, 3, 5, 1, 1, 6, 5, 1, 2, 3, 2, 5, 3, 2]\n",
      "[1, 1, 1, 3, 2, 3, 2, 3, 1, 6, 1, 1, 1, 3, 2, 3, 2, 1, 2, 1, 1, 1, 2, 3, 1, 3, 1, 3, 1, 1, 1, 1, 1, 3, 1, 3, 1, 2, 1, 2, 1, 2, 1, 3, 2, 3, 2, 2, 2, 2, 1, 1, 2, 2, 2, 3, 2, 2, 2, 3, 1, 3, 2, 3, 1, 3, 1, 3, 1, 1, 1, 3, 1, 3, 1, 2, 1, 2, 1, 2, 1, 3, 2, 3, 2, 3, 2, 2, 1, 2, 2, 3, 2, 3, 2, 3, 2, 2, 2, 1, 2, 3, 2, 3, 2, 3, 1, 3, 1, 1, 1, 3, 1, 3, 1, 3, 1, 2, 1, 3, 1, 3, 2, 3, 2, 3, 2, 2, 1, 1, 1, 2, 2, 3, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_to_labels(y_labels, arr):\n",
    "   \n",
    "    # Convert predictions to class indices\n",
    "    classes = np.argmax(arr, axis=1)\n",
    "    \n",
    "    labels =   [y_labels[i] for i in classes]\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "predictions_labels = convert_to_labels(y_labels , predictions)\n",
    "y_test_labels = convert_to_labels(y_labels, y_test)\n",
    "\n",
    "print(\"all prediction\")\n",
    "print(y_test_labels)\n",
    "print(predictions_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cj2\n",
      "[1, 6, 1, 2, 4, 1, 1, 6, 4, 6, 5, 6, 5, 6, 5, 1, 3, 6, 2, 1, 1, 1, 4, 6, 2, 1, 5, 6, 4, 6, 4, 2, 2, 3, 5, 6, 2, 2, 5, 2, 3, 6, 5, 6, 2, 3, 5, 6, 4, 6, 3, 6, 2, 6, 5, 1, 1, 6, 5, 2, 4, 6, 3, 6, 4, 2, 2, 3, 1, 6, 1, 3, 5, 2]\n",
      "[1, 3, 3, 3, 6, 1, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 3, 3, 2, 2, 2, 3, 3, 2, 2, 1, 2, 3, 2, 3, 3, 3, 3, 3, 1, 3, 3, 2, 2, 2, 3, 3, 3, 2, 2, 3, 3, 3, 2, 1, 3, 3, 3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 2, 1, 2, 3, 2, 2, 1, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "def make_pair(arr):\n",
    "    if len(arr) % 2 == 0:\n",
    "        arr = arr\n",
    "    else:\n",
    "        arr = arr[1:] \n",
    "    return arr\n",
    "\n",
    "pr = make_pair(predictions_labels)\n",
    "real = make_pair(y_test_labels)\n",
    "\n",
    "\n",
    "pr_cj = []\n",
    "real_cj = []\n",
    "\n",
    "for i in range(len(pr)):\n",
    "    if i % 2 != 0:\n",
    "        pr_cj.append(pr[i])\n",
    "        real_cj.append(real[i])\n",
    "\n",
    "\n",
    "print(\"cj2\")\n",
    "print(real_cj)\n",
    "print(pr_cj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc =  0.5472972972972973\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_accuracy(arr1, arr2):\n",
    "    gr1 = [2,3, 1]\n",
    "    gr2 = [4,5,6]\n",
    "    if len(arr1) != len(arr2):\n",
    "        raise ValueError(\"Arrays must have the same length\")\n",
    "    \n",
    "    arr1 = list(map(int, arr1))\n",
    "    arr2 = list(map(int, arr2))\n",
    "    \n",
    "    correct_predictions = sum((a in gr1 and b in  gr1) or (a in gr2 and b in  gr2) for a, b in zip(arr1, arr2))\n",
    "    accuracy = correct_predictions / len(arr1)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "print(\"acc = \", calculate_accuracy(y_test_labels, predictions_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20, 8)\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(X_last.shape)\n",
    "\n",
    "predictions_last = model.predict([X_last])\n",
    "print(convert_to_labels(y_labels,  predictions_last))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
