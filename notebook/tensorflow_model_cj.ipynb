{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 21:28:34.069019: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-26 21:28:34.195206: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-26 21:28:34.197063: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-26 21:28:35.007281: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>2022-12-09 00:00:00</th>\n",
       "      <th>2022-12-12 00:00:00</th>\n",
       "      <th>2022-12-13 00:00:00</th>\n",
       "      <th>2022-12-14 00:00:00</th>\n",
       "      <th>2022-12-15 00:00:00</th>\n",
       "      <th>2022-12-16 00:00:00</th>\n",
       "      <th>2022-12-19 00:00:00</th>\n",
       "      <th>2022-12-20 00:00:00</th>\n",
       "      <th>2022-12-21 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2024-07-10 00:00:00</th>\n",
       "      <th>2024-07-11 00:00:00</th>\n",
       "      <th>2024-07-12 00:00:00</th>\n",
       "      <th>2024-07-15 00:00:00</th>\n",
       "      <th>2024-07-16 00:00:00</th>\n",
       "      <th>2024-07-17 00:00:00</th>\n",
       "      <th>2024-07-18 00:00:00</th>\n",
       "      <th>2024-07-19 00:00:00</th>\n",
       "      <th>2024-07-22 00:00:00</th>\n",
       "      <th>2024-07-23 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CJ1</td>\n",
       "      <td>0.42857142857142855 | 1 | 9.298351223306579 | ...</td>\n",
       "      <td>0.2857142857142857 | 4 | 9.408758093067364 | 1...</td>\n",
       "      <td>0.2857142857142857 | 4 | 10.797831461587762 | ...</td>\n",
       "      <td>0.14285714285714285 | 1 | -5.1197895052942926 ...</td>\n",
       "      <td>0.14285714285714285 | 1 | -11.585323970828755 ...</td>\n",
       "      <td>0.14285714285714285 | 3 | -9.580096998238858 |...</td>\n",
       "      <td>0.2857142857142857 | 1 | -14.439119554629839 |...</td>\n",
       "      <td>0.5714285714285714 | 4 | -12.694417705198628 |...</td>\n",
       "      <td>0.8571428571428571 | 4 | -12.410368284980738 |...</td>\n",
       "      <td>...</td>\n",
       "      <td>15.142857142857142 | 6 | -4.195921480477438 | ...</td>\n",
       "      <td>15.0 | 3 | -4.567419080176236 | 53672 | 1.0459...</td>\n",
       "      <td>14.571428571428571 | 3 | -1.8136530302318334 |...</td>\n",
       "      <td>14.142857142857142 | 1 | -1.8399861441225482 |...</td>\n",
       "      <td>13.714285714285714 | 2 | 1.7579084985482183 | ...</td>\n",
       "      <td>13.428571428571429 | 6 | 13.731127120625501 | ...</td>\n",
       "      <td>13.142857142857142 | 3 | 15.737952502343816 | ...</td>\n",
       "      <td>12.571428571428571 | 7 | 20.35340232151198 | 2...</td>\n",
       "      <td>12.0 | 3 | 18.552667676448053 | 19558 | -0.074...</td>\n",
       "      <td>11.428571428571429 | 2 | 21.869661140500313 | ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CJ2</td>\n",
       "      <td>0.0 | 4 | 6.9552124790735155 | 1224919 | 22.56...</td>\n",
       "      <td>-0.14285714285714285 | 3 | -3.214907049606437 ...</td>\n",
       "      <td>0.0 | 6 | 12.559889744426675 | 1605059 | 22.60...</td>\n",
       "      <td>0.2857142857142857 | 1 | -3.310052782066485 | ...</td>\n",
       "      <td>0.42857142857142855 | 2 | 9.3771399051262 | 16...</td>\n",
       "      <td>0.42857142857142855 | 1 | 8.254784426908245 | ...</td>\n",
       "      <td>0.42857142857142855 | 1 | 8.954544312040364 | ...</td>\n",
       "      <td>0.42857142857142855 | 6 | 20.756073391792295 |...</td>\n",
       "      <td>0.5714285714285714 | 1 | 13.14174140798663 | 1...</td>\n",
       "      <td>...</td>\n",
       "      <td>14.857142857142858 | 1 | 11.359328002698149 | ...</td>\n",
       "      <td>14.857142857142858 | 6 | 28.957783190077038 | ...</td>\n",
       "      <td>14.857142857142858 | 4 | 17.385475692228724 | ...</td>\n",
       "      <td>15.0 | 5 | 29.71836602378295 | 1469179 | 19.15...</td>\n",
       "      <td>15.428571428571429 | 6 | 25.697360807788996 | ...</td>\n",
       "      <td>15.857142857142858 | 3 | 20.94173402435338 | 1...</td>\n",
       "      <td>16.142857142857142 | 2 | 26.78903637483633 | 1...</td>\n",
       "      <td>16.285714285714285 | 2 | 40.60484476666744 | 1...</td>\n",
       "      <td>16.142857142857142 | 3 | 26.18158806752625 | 1...</td>\n",
       "      <td>15.857142857142858 | 1 | 24.50784242713813 | 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 418 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  DATE                                2022-12-09 00:00:00  \\\n",
       "0  CJ1  0.42857142857142855 | 1 | 9.298351223306579 | ...   \n",
       "1  CJ2  0.0 | 4 | 6.9552124790735155 | 1224919 | 22.56...   \n",
       "\n",
       "                                 2022-12-12 00:00:00  \\\n",
       "0  0.2857142857142857 | 4 | 9.408758093067364 | 1...   \n",
       "1  -0.14285714285714285 | 3 | -3.214907049606437 ...   \n",
       "\n",
       "                                 2022-12-13 00:00:00  \\\n",
       "0  0.2857142857142857 | 4 | 10.797831461587762 | ...   \n",
       "1  0.0 | 6 | 12.559889744426675 | 1605059 | 22.60...   \n",
       "\n",
       "                                 2022-12-14 00:00:00  \\\n",
       "0  0.14285714285714285 | 1 | -5.1197895052942926 ...   \n",
       "1  0.2857142857142857 | 1 | -3.310052782066485 | ...   \n",
       "\n",
       "                                 2022-12-15 00:00:00  \\\n",
       "0  0.14285714285714285 | 1 | -11.585323970828755 ...   \n",
       "1  0.42857142857142855 | 2 | 9.3771399051262 | 16...   \n",
       "\n",
       "                                 2022-12-16 00:00:00  \\\n",
       "0  0.14285714285714285 | 3 | -9.580096998238858 |...   \n",
       "1  0.42857142857142855 | 1 | 8.254784426908245 | ...   \n",
       "\n",
       "                                 2022-12-19 00:00:00  \\\n",
       "0  0.2857142857142857 | 1 | -14.439119554629839 |...   \n",
       "1  0.42857142857142855 | 1 | 8.954544312040364 | ...   \n",
       "\n",
       "                                 2022-12-20 00:00:00  \\\n",
       "0  0.5714285714285714 | 4 | -12.694417705198628 |...   \n",
       "1  0.42857142857142855 | 6 | 20.756073391792295 |...   \n",
       "\n",
       "                                 2022-12-21 00:00:00  ...  \\\n",
       "0  0.8571428571428571 | 4 | -12.410368284980738 |...  ...   \n",
       "1  0.5714285714285714 | 1 | 13.14174140798663 | 1...  ...   \n",
       "\n",
       "                                 2024-07-10 00:00:00  \\\n",
       "0  15.142857142857142 | 6 | -4.195921480477438 | ...   \n",
       "1  14.857142857142858 | 1 | 11.359328002698149 | ...   \n",
       "\n",
       "                                 2024-07-11 00:00:00  \\\n",
       "0  15.0 | 3 | -4.567419080176236 | 53672 | 1.0459...   \n",
       "1  14.857142857142858 | 6 | 28.957783190077038 | ...   \n",
       "\n",
       "                                 2024-07-12 00:00:00  \\\n",
       "0  14.571428571428571 | 3 | -1.8136530302318334 |...   \n",
       "1  14.857142857142858 | 4 | 17.385475692228724 | ...   \n",
       "\n",
       "                                 2024-07-15 00:00:00  \\\n",
       "0  14.142857142857142 | 1 | -1.8399861441225482 |...   \n",
       "1  15.0 | 5 | 29.71836602378295 | 1469179 | 19.15...   \n",
       "\n",
       "                                 2024-07-16 00:00:00  \\\n",
       "0  13.714285714285714 | 2 | 1.7579084985482183 | ...   \n",
       "1  15.428571428571429 | 6 | 25.697360807788996 | ...   \n",
       "\n",
       "                                 2024-07-17 00:00:00  \\\n",
       "0  13.428571428571429 | 6 | 13.731127120625501 | ...   \n",
       "1  15.857142857142858 | 3 | 20.94173402435338 | 1...   \n",
       "\n",
       "                                 2024-07-18 00:00:00  \\\n",
       "0  13.142857142857142 | 3 | 15.737952502343816 | ...   \n",
       "1  16.142857142857142 | 2 | 26.78903637483633 | 1...   \n",
       "\n",
       "                                 2024-07-19 00:00:00  \\\n",
       "0  12.571428571428571 | 7 | 20.35340232151198 | 2...   \n",
       "1  16.285714285714285 | 2 | 40.60484476666744 | 1...   \n",
       "\n",
       "                                 2024-07-22 00:00:00  \\\n",
       "0  12.0 | 3 | 18.552667676448053 | 19558 | -0.074...   \n",
       "1  16.142857142857142 | 3 | 26.18158806752625 | 1...   \n",
       "\n",
       "                                 2024-07-23 00:00:00  \n",
       "0  11.428571428571429 | 2 | 21.869661140500313 | ...  \n",
       "1  15.857142857142858 | 1 | 24.50784242713813 | 1...  \n",
       "\n",
       "[2 rows x 418 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Pandas library\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.lib_cj import CjModel\n",
    "\n",
    "model = CjModel()\n",
    "path = \"../test_data/data_v3.xlsx\"\n",
    "\n",
    "combined_df = model.preprocess_excel(path)\n",
    "\n",
    "combined_df\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>date</th>\n",
       "      <th>all_values</th>\n",
       "      <th>name_code</th>\n",
       "      <th>date_as_int</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CJ1</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>0.42857142857142855 | 1 | 9.298351223306579 | ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1670544000</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>343</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.298351</td>\n",
       "      <td>184733.0</td>\n",
       "      <td>-3.272231</td>\n",
       "      <td>-2.546509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CJ2</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>0.0 | 4 | 6.9552124790735155 | 1224919 | 22.56...</td>\n",
       "      <td>2</td>\n",
       "      <td>1670544000</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.955212</td>\n",
       "      <td>1224919.0</td>\n",
       "      <td>22.568973</td>\n",
       "      <td>22.145818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CJ1</td>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>0.2857142857142857 | 4 | 9.408758093067364 | 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>1670803200</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>346</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.408758</td>\n",
       "      <td>167139.0</td>\n",
       "      <td>-3.266928</td>\n",
       "      <td>-2.690592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CJ2</td>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>-0.14285714285714285 | 3 | -3.214907049606437 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1670803200</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>346</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.214907</td>\n",
       "      <td>1091707.0</td>\n",
       "      <td>21.398682</td>\n",
       "      <td>21.996391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CJ1</td>\n",
       "      <td>2022-12-13</td>\n",
       "      <td>0.2857142857142857 | 4 | 10.797831461587762 | ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1670889600</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.797831</td>\n",
       "      <td>138497.0</td>\n",
       "      <td>-3.073259</td>\n",
       "      <td>-2.767126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>CJ2</td>\n",
       "      <td>2024-07-19</td>\n",
       "      <td>16.285714285714285 | 2 | 40.60484476666744 | 1...</td>\n",
       "      <td>2</td>\n",
       "      <td>1721347200</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>201</td>\n",
       "      <td>16.285714</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.604845</td>\n",
       "      <td>1632606.0</td>\n",
       "      <td>26.869091</td>\n",
       "      <td>20.375216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>CJ1</td>\n",
       "      <td>2024-07-22</td>\n",
       "      <td>12.0 | 3 | 18.552667676448053 | 19558 | -0.074...</td>\n",
       "      <td>1</td>\n",
       "      <td>1721606400</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.552668</td>\n",
       "      <td>19558.0</td>\n",
       "      <td>-0.074731</td>\n",
       "      <td>0.520711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>CJ2</td>\n",
       "      <td>2024-07-22</td>\n",
       "      <td>16.142857142857142 | 3 | 26.18158806752625 | 1...</td>\n",
       "      <td>2</td>\n",
       "      <td>1721606400</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>16.142857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.181588</td>\n",
       "      <td>1465395.0</td>\n",
       "      <td>24.135455</td>\n",
       "      <td>21.127264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>CJ1</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>11.428571428571429 | 2 | 21.869661140500313 | ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1721692800</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.869661</td>\n",
       "      <td>19414.0</td>\n",
       "      <td>-0.337773</td>\n",
       "      <td>0.349014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>CJ2</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>15.857142857142858 | 1 | 24.50784242713813 | 1...</td>\n",
       "      <td>2</td>\n",
       "      <td>1721692800</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "      <td>15.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.507842</td>\n",
       "      <td>1434186.0</td>\n",
       "      <td>22.636048</td>\n",
       "      <td>21.429021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>834 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    DATE       date                                         all_values  \\\n",
       "0    CJ1 2022-12-09  0.42857142857142855 | 1 | 9.298351223306579 | ...   \n",
       "1    CJ2 2022-12-09  0.0 | 4 | 6.9552124790735155 | 1224919 | 22.56...   \n",
       "2    CJ1 2022-12-12  0.2857142857142857 | 4 | 9.408758093067364 | 1...   \n",
       "3    CJ2 2022-12-12  -0.14285714285714285 | 3 | -3.214907049606437 ...   \n",
       "4    CJ1 2022-12-13  0.2857142857142857 | 4 | 10.797831461587762 | ...   \n",
       "..   ...        ...                                                ...   \n",
       "829  CJ2 2024-07-19  16.285714285714285 | 2 | 40.60484476666744 | 1...   \n",
       "830  CJ1 2024-07-22  12.0 | 3 | 18.552667676448053 | 19558 | -0.074...   \n",
       "831  CJ2 2024-07-22  16.142857142857142 | 3 | 26.18158806752625 | 1...   \n",
       "832  CJ1 2024-07-23  11.428571428571429 | 2 | 21.869661140500313 | ...   \n",
       "833  CJ2 2024-07-23  15.857142857142858 | 1 | 24.50784242713813 | 1...   \n",
       "\n",
       "     name_code  date_as_int  day_of_month  day_of_week  day_of_year  \\\n",
       "0            1   1670544000             9            4          343   \n",
       "1            2   1670544000             9            4          343   \n",
       "2            1   1670803200            12            0          346   \n",
       "3            2   1670803200            12            0          346   \n",
       "4            1   1670889600            13            1          347   \n",
       "..         ...          ...           ...          ...          ...   \n",
       "829          2   1721347200            19            4          201   \n",
       "830          1   1721606400            22            0          204   \n",
       "831          2   1721606400            22            0          204   \n",
       "832          1   1721692800            23            1          205   \n",
       "833          2   1721692800            23            1          205   \n",
       "\n",
       "            v1   v2         v3         v4         v5         v6  \n",
       "0     0.428571  1.0   9.298351   184733.0  -3.272231  -2.546509  \n",
       "1     0.000000  4.0   6.955212  1224919.0  22.568973  22.145818  \n",
       "2     0.285714  4.0   9.408758   167139.0  -3.266928  -2.690592  \n",
       "3    -0.142857  3.0  -3.214907  1091707.0  21.398682  21.996391  \n",
       "4     0.285714  4.0  10.797831   138497.0  -3.073259  -2.767126  \n",
       "..         ...  ...        ...        ...        ...        ...  \n",
       "829  16.285714  2.0  40.604845  1632606.0  26.869091  20.375216  \n",
       "830  12.000000  3.0  18.552668    19558.0  -0.074731   0.520711  \n",
       "831  16.142857  3.0  26.181588  1465395.0  24.135455  21.127264  \n",
       "832  11.428571  2.0  21.869661    19414.0  -0.337773   0.349014  \n",
       "833  15.857143  1.0  24.507842  1434186.0  22.636048  21.429021  \n",
       "\n",
       "[834 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "long_df = model.process_data(combined_df)\n",
    "\n",
    "long_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(407, 10, 11)\n",
      "(407, 7)\n",
      "(1, 10, 11)\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 2s 8ms/step - loss: 2.7281 - accuracy: 0.1415\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.4971 - accuracy: 0.1815\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.4251 - accuracy: 0.2092\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.3430 - accuracy: 0.2062\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.2759 - accuracy: 0.2092\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.2909 - accuracy: 0.2092\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 2.1163 - accuracy: 0.2277\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.2420 - accuracy: 0.2369\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.2653 - accuracy: 0.2092\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.1383 - accuracy: 0.2308\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.1072 - accuracy: 0.2554\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9858 - accuracy: 0.2462\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.0324 - accuracy: 0.2338\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.0159 - accuracy: 0.2338\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.9917 - accuracy: 0.2677\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9855 - accuracy: 0.2585\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.0227 - accuracy: 0.2523\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9399 - accuracy: 0.2646\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9163 - accuracy: 0.2862\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9449 - accuracy: 0.2769\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9544 - accuracy: 0.2646\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9186 - accuracy: 0.2492\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.8750 - accuracy: 0.3046\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.8805 - accuracy: 0.2769\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.8560 - accuracy: 0.2985\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.8901 - accuracy: 0.3292\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.8850 - accuracy: 0.2985\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.8875 - accuracy: 0.3046\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.8546 - accuracy: 0.2677\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.8087 - accuracy: 0.3077\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7654 - accuracy: 0.3508\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7860 - accuracy: 0.3415\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7638 - accuracy: 0.3077\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7861 - accuracy: 0.3354\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7457 - accuracy: 0.2985\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7776 - accuracy: 0.3015\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.7273 - accuracy: 0.3138\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7560 - accuracy: 0.3231\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.7031 - accuracy: 0.3354\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7709 - accuracy: 0.3231\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6892 - accuracy: 0.3446\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6704 - accuracy: 0.3600\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7992 - accuracy: 0.3077\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.7298 - accuracy: 0.3262\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6801 - accuracy: 0.3446\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7078 - accuracy: 0.3077\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6693 - accuracy: 0.3508\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6909 - accuracy: 0.3600\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6259 - accuracy: 0.3723\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7335 - accuracy: 0.3108\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7314 - accuracy: 0.3323\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6827 - accuracy: 0.3385\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6285 - accuracy: 0.3415\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6134 - accuracy: 0.3600\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.7210 - accuracy: 0.3477\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6292 - accuracy: 0.3908\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6275 - accuracy: 0.3662\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6738 - accuracy: 0.3415\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6460 - accuracy: 0.3600\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6781 - accuracy: 0.3692\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6510 - accuracy: 0.3631\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6666 - accuracy: 0.3262\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6654 - accuracy: 0.3569\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6363 - accuracy: 0.4215\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6585 - accuracy: 0.3538\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5808 - accuracy: 0.4369\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5928 - accuracy: 0.3908\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6956 - accuracy: 0.3415\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5693 - accuracy: 0.3938\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6773 - accuracy: 0.3231\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5912 - accuracy: 0.4092\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5904 - accuracy: 0.3692\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6193 - accuracy: 0.3785\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6141 - accuracy: 0.3815\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6277 - accuracy: 0.3631\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6059 - accuracy: 0.3754\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5965 - accuracy: 0.3815\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5670 - accuracy: 0.4123\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5661 - accuracy: 0.3877\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6047 - accuracy: 0.3969\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6209 - accuracy: 0.3969\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6080 - accuracy: 0.3538\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5701 - accuracy: 0.3692\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5665 - accuracy: 0.4031\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5387 - accuracy: 0.3785\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5504 - accuracy: 0.4246\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5903 - accuracy: 0.3938\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5291 - accuracy: 0.4185\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5621 - accuracy: 0.4062\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5722 - accuracy: 0.3846\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5429 - accuracy: 0.4000\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5699 - accuracy: 0.4308\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5605 - accuracy: 0.3600\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5310 - accuracy: 0.3846\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5692 - accuracy: 0.3908\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5099 - accuracy: 0.4554\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5264 - accuracy: 0.4308\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5497 - accuracy: 0.4031\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5552 - accuracy: 0.4092\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5216 - accuracy: 0.4585\n",
      "Training Accuracy: 0.5754\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Test Accuracy: 0.2439\n",
      "(407, 10, 11)\n",
      "(407, 7)\n",
      "(1, 10, 11)\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 2s 8ms/step - loss: 2.6522 - accuracy: 0.1323\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.5542 - accuracy: 0.1908\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 2.6081 - accuracy: 0.1662\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 2.4855 - accuracy: 0.1846\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.3341 - accuracy: 0.1600\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 2.3773 - accuracy: 0.2092\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 2.2552 - accuracy: 0.2092\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.1556 - accuracy: 0.1969\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.1723 - accuracy: 0.1846\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.1570 - accuracy: 0.2123\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.0049 - accuracy: 0.2338\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.0126 - accuracy: 0.2554\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.9836 - accuracy: 0.2523\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0736 - accuracy: 0.2646\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.0125 - accuracy: 0.2708\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9654 - accuracy: 0.2738\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9934 - accuracy: 0.2462\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9503 - accuracy: 0.2554\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0537 - accuracy: 0.2400\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9421 - accuracy: 0.2769\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.0086 - accuracy: 0.2277\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9269 - accuracy: 0.2800\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9162 - accuracy: 0.2892\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.8709 - accuracy: 0.3015\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.8232 - accuracy: 0.3108\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.9467 - accuracy: 0.2738\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.9206 - accuracy: 0.3108\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.8744 - accuracy: 0.2923\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.8806 - accuracy: 0.2892\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.8672 - accuracy: 0.2769\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.8403 - accuracy: 0.3046\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.8462 - accuracy: 0.2769\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7802 - accuracy: 0.3385\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.8267 - accuracy: 0.3354\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7723 - accuracy: 0.3385\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7512 - accuracy: 0.3538\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.7874 - accuracy: 0.3323\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.8438 - accuracy: 0.2800\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.7009 - accuracy: 0.3538\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7766 - accuracy: 0.3323\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7421 - accuracy: 0.3538\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7165 - accuracy: 0.3108\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.8267 - accuracy: 0.3385\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.7838 - accuracy: 0.3415\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.8121 - accuracy: 0.3169\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.7500 - accuracy: 0.3477\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.7807 - accuracy: 0.2862\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7015 - accuracy: 0.3446\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.7316 - accuracy: 0.3046\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7195 - accuracy: 0.3292\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.6978 - accuracy: 0.3538\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.7055 - accuracy: 0.3508\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.7090 - accuracy: 0.3477\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7473 - accuracy: 0.3538\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6977 - accuracy: 0.3569\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7128 - accuracy: 0.3262\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.7095 - accuracy: 0.3200\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6585 - accuracy: 0.3477\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6761 - accuracy: 0.3538\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6584 - accuracy: 0.3877\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6300 - accuracy: 0.3631\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6004 - accuracy: 0.3785\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6708 - accuracy: 0.3723\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5989 - accuracy: 0.3692\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6548 - accuracy: 0.3754\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6266 - accuracy: 0.3815\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.7516 - accuracy: 0.3415\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6654 - accuracy: 0.3631\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5801 - accuracy: 0.4154\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5705 - accuracy: 0.3846\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6310 - accuracy: 0.3415\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6032 - accuracy: 0.3938\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5594 - accuracy: 0.4062\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5715 - accuracy: 0.3785\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5739 - accuracy: 0.4277\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6497 - accuracy: 0.3631\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6111 - accuracy: 0.3785\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5819 - accuracy: 0.3877\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5254 - accuracy: 0.4185\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5606 - accuracy: 0.4092\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5769 - accuracy: 0.4215\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5712 - accuracy: 0.4031\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5508 - accuracy: 0.4000\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5631 - accuracy: 0.3477\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5222 - accuracy: 0.4246\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5121 - accuracy: 0.4123\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5614 - accuracy: 0.4092\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5694 - accuracy: 0.3938\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5431 - accuracy: 0.4031\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5581 - accuracy: 0.3938\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5082 - accuracy: 0.4031\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5218 - accuracy: 0.4123\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5211 - accuracy: 0.4246\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4799 - accuracy: 0.4462\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5445 - accuracy: 0.3969\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5489 - accuracy: 0.4062\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5324 - accuracy: 0.4185\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5007 - accuracy: 0.4277\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5188 - accuracy: 0.4123\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.4866 - accuracy: 0.4462\n",
      "Training Accuracy: 0.6400\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Test Accuracy: 0.1707\n"
     ]
    }
   ],
   "source": [
    "X, y, last_X = model.make_train_data(long_df, 1)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(last_X.shape)\n",
    "predictions_labels , y_test_labels , predictions , y_test = model.fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "X, y, last_X = model.make_train_data(long_df, 2)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(last_X.shape)\n",
    "predictions_labels , y_test_labels , predictions , y_test = model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]; [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]; [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]; [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]; [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]; [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]; [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]; [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]; [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]; [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]; [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]; [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]; [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]; [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]; [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]; [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]; [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]; [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]; [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]; [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]; [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]; [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]; [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]; [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]; [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]; [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]; [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]; [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.32614535, 0.15101384, 0.05955847, 0.0708188, 0.057931315, 0.12968089, 0.20485133]; [0.18194743, 0.17604208, 0.092124976, 0.13749872, 0.08849841, 0.14984377, 0.17404462]; [0.16408715, 0.11536001, 0.16992852, 0.119777605, 0.118264936, 0.18052512, 0.1320567]; [0.30818412, 0.10093008, 0.14447324, 0.07647994, 0.07902482, 0.15131126, 0.13959657]; [0.43515906, 0.09372906, 0.039486673, 0.050163176, 0.0478563, 0.07583754, 0.25776827]; [0.54172575, 0.062771685, 0.03546392, 0.036768537, 0.035674233, 0.059140243, 0.2284556]; [0.26061016, 0.12865068, 0.08852856, 0.10218539, 0.07481207, 0.14327587, 0.2019372]; [0.33523446, 0.14318186, 0.058252078, 0.06307187, 0.069807924, 0.12834999, 0.20210186]; [0.2497965, 0.16754141, 0.03304096, 0.09147318, 0.033725988, 0.14496273, 0.27945918]; [0.2882408, 0.27791545, 0.010500662, 0.034799185, 0.025503855, 0.10148444, 0.2615555]; [0.5116062, 0.11784046, 0.009180737, 0.03670508, 0.020950489, 0.06326469, 0.24045233]; [0.24583967, 0.20011945, 0.022546353, 0.11894462, 0.05273513, 0.11641388, 0.24340093]; [0.2796834, 0.20363037, 0.021126697, 0.07585385, 0.06281379, 0.14809585, 0.20879592]; [0.3238547, 0.122178726, 0.021657862, 0.1077543, 0.04391664, 0.16506758, 0.2155701]; [0.3714721, 0.17102556, 0.0066041998, 0.119873114, 0.017547755, 0.1176218, 0.19585545]; [0.30788186, 0.21436079, 0.007569885, 0.08599593, 0.02448546, 0.12743562, 0.23227029]; [0.20353942, 0.23881032, 0.026888775, 0.11008263, 0.04440498, 0.20980999, 0.16646384]; [0.16648474, 0.24390899, 0.038436983, 0.100047104, 0.060926285, 0.23894005, 0.15125586]; [0.1491847, 0.23789838, 0.023468213, 0.11132931, 0.038146567, 0.29638627, 0.14358655]; [0.19035342, 0.2564657, 0.0078118043, 0.18574367, 0.016765403, 0.21159492, 0.13126518]; [0.21918374, 0.23138233, 0.01685164, 0.10576686, 0.030426592, 0.20880789, 0.18758093]; [0.17093079, 0.23943894, 0.05132129, 0.08939116, 0.06474057, 0.2525793, 0.13159803]; [0.14298703, 0.17888834, 0.102049775, 0.09637729, 0.09565059, 0.28950906, 0.09453784]; [0.10268833, 0.28621247, 0.0408852, 0.105031766, 0.05280236, 0.24755765, 0.16482227]; [0.20115522, 0.2604488, 0.023863474, 0.06670214, 0.05438551, 0.17709969, 0.21634519]; [0.3265123, 0.16725333, 0.031406276, 0.052654196, 0.0661506, 0.13629287, 0.21973033]; [0.2864087, 0.13988616, 0.070634365, 0.094457224, 0.08031154, 0.1263069, 0.20199507]; [0.4136596, 0.11757165, 0.05743078, 0.04294049, 0.07652667, 0.12511866, 0.16675222]; [0.27000135, 0.1382467, 0.10150567, 0.07856776, 0.04652766, 0.12045652, 0.2446944]; [0.20392078, 0.34307313, 0.03545354, 0.07679454, 0.05211175, 0.14568497, 0.14296125]; [0.24272552, 0.24674663, 0.043762784, 0.056065015, 0.05829204, 0.15025525, 0.2021527]; [0.23257963, 0.2574515, 0.06839322, 0.037054203, 0.08419446, 0.1735107, 0.14681618]; [0.2618116, 0.26783073, 0.06981814, 0.06190542, 0.058251984, 0.14467898, 0.13570319]; [0.27568802, 0.16514185, 0.1464537, 0.059190158, 0.058514018, 0.13978726, 0.15522519]; [0.50352985, 0.12082884, 0.032304212, 0.08376871, 0.03555125, 0.060636315, 0.16338076]; [0.48273185, 0.08897461, 0.041198358, 0.060007706, 0.045800168, 0.07464666, 0.20664065]; [0.14281157, 0.15697113, 0.15449141, 0.110770814, 0.127168, 0.18174483, 0.1260423]; [0.1169669, 0.11713405, 0.23480266, 0.06972277, 0.1526882, 0.21799931, 0.0906861]; [0.16609983, 0.15675218, 0.16634877, 0.117879055, 0.07443371, 0.18066537, 0.13782108]; [0.29442748, 0.15992875, 0.04068282, 0.089876436, 0.058454633, 0.16230287, 0.19432703]; [0.45158195, 0.060276203, 0.03856269, 0.095564626, 0.054949235, 0.098819144, 0.2002461]; [0.0999717, 0.11916561, 0.16849749, 0.1678099, 0.15105008, 0.20115061, 0.09235461]; [0.04148853, 0.11484173, 0.2502597, 0.087665826, 0.23627284, 0.22243372, 0.04703762]; [0.059042685, 0.09159831, 0.31447113, 0.094208635, 0.14425558, 0.25099966, 0.045424063]; [0.121868715, 0.30957013, 0.05770101, 0.08856393, 0.09957563, 0.22873816, 0.093982436]; [0.18118773, 0.21649374, 0.07969825, 0.08599261, 0.12110433, 0.20613809, 0.10938522]; [0.021520743, 0.117536195, 0.18128915, 0.23098351, 0.16998713, 0.23738012, 0.04130311]; [0.049078267, 0.10479774, 0.31395707, 0.108514, 0.17969047, 0.18359517, 0.060367227]; [0.26604018, 0.09662484, 0.24990155, 0.06376346, 0.07858974, 0.13858396, 0.10649631]; [0.22044773, 0.15656984, 0.1324242, 0.07812102, 0.124476455, 0.13730294, 0.15065783]; [0.25262126, 0.14747399, 0.08160999, 0.10374823, 0.13318889, 0.10747802, 0.17387961]; [0.070979014, 0.11981769, 0.30926824, 0.117472656, 0.111395344, 0.18105303, 0.09001404]; [0.10129866, 0.14168853, 0.17303513, 0.19403183, 0.0898582, 0.14431036, 0.15577732]; [0.03338684, 0.086508274, 0.3343148, 0.24152337, 0.051150214, 0.20451804, 0.048598506]; [0.29248336, 0.12732211, 0.0905059, 0.091776304, 0.07986862, 0.087035045, 0.23100854]; [0.6808176, 0.047164634, 0.025186084, 0.14881109, 0.012816517, 0.016959077, 0.06824505]; [0.17672183, 0.31889027, 0.074649185, 0.08297593, 0.027195966, 0.16879162, 0.15077525]; [0.088095546, 0.2474539, 0.12789044, 0.23770861, 0.05357572, 0.15698415, 0.08829161]; [0.160969, 0.13082545, 0.2594882, 0.14979765, 0.03659676, 0.1855701, 0.0767528]; [0.25711894, 0.15614428, 0.08699645, 0.2212845, 0.046552997, 0.11215691, 0.11974579]; [0.13199739, 0.22952217, 0.14368963, 0.1429101, 0.095565125, 0.14023663, 0.116078936]; [0.12839742, 0.2418027, 0.137776, 0.09970622, 0.09312592, 0.1680013, 0.13119048]; [0.06503829, 0.22072193, 0.16055351, 0.1700737, 0.06309129, 0.26781228, 0.052709043]; [0.056160696, 0.07345209, 0.3327372, 0.16297972, 0.044780042, 0.27441326, 0.055476997]; [0.15045208, 0.14479409, 0.1610912, 0.15793845, 0.1431446, 0.14628154, 0.096298024]; [0.2315751, 0.09662694, 0.17004031, 0.11913675, 0.08103463, 0.19191878, 0.10966751]; [0.03807098, 0.18338919, 0.20030591, 0.1136183, 0.16341868, 0.23274879, 0.068448156]; [0.037561234, 0.18745314, 0.2609212, 0.1323811, 0.11434055, 0.2090083, 0.058334507]; [0.11684729, 0.12084625, 0.27882767, 0.11540805, 0.05496145, 0.22018495, 0.09292434]; [0.22410546, 0.23717949, 0.086731106, 0.11542874, 0.11271457, 0.106211275, 0.11762925]; [0.19956395, 0.26951835, 0.07225859, 0.15531868, 0.07262516, 0.1181408, 0.11257447]; [0.053447682, 0.17232767, 0.3122228, 0.09316716, 0.07631912, 0.23533846, 0.057177003]; [0.10713019, 0.16790885, 0.23475839, 0.093690544, 0.089657255, 0.19109082, 0.11576393]; [0.061885774, 0.099147126, 0.3658202, 0.095400155, 0.036882933, 0.27041608, 0.07044785]; [0.24325493, 0.16089335, 0.12820815, 0.08602706, 0.085182354, 0.11903001, 0.17740418]; [0.4619456, 0.08248429, 0.0852707, 0.108130954, 0.056454226, 0.063613534, 0.14210081]; [0.2127525, 0.19114123, 0.11514788, 0.08829269, 0.0698203, 0.17183748, 0.1510079]; [0.064368196, 0.13950029, 0.2222682, 0.11557952, 0.13376045, 0.24567646, 0.07884692]; [0.122378595, 0.1428266, 0.20771994, 0.11564724, 0.08285994, 0.21977921, 0.10878852]; [0.32616854, 0.11263636, 0.06100755, 0.104125634, 0.06468339, 0.15791136, 0.17346717]; [0.43664035, 0.06500303, 0.051729262, 0.12242659, 0.058700174, 0.10045192, 0.16504861]; [0.17048709, 0.12240738, 0.14370526, 0.09607753, 0.1826464, 0.20301183, 0.081664495]\n"
     ]
    }
   ],
   "source": [
    "def join_2d_array_with_semicolon(arr):\n",
    "    # Convert each row to a string in the desired format\n",
    "    rows = ['[' + ', '.join(map(str, row)) + ']' for row in arr]\n",
    "    # Join all rows with a semicolon\n",
    "    return '; '.join(rows)\n",
    "\n",
    "print(join_2d_array_with_semicolon(y_test))\n",
    "print(join_2d_array_with_semicolon(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21951219512195122\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(arr1, arr2):\n",
    "    gr1 = [1]\n",
    "    gr2 =  [2,3, 7]\n",
    "    gr3 = [4,5,6]\n",
    "    if len(arr1) != len(arr2):\n",
    "        raise ValueError(\"Arrays must have the same length\")\n",
    "    \n",
    "    arr1 = list(map(int, arr1))\n",
    "    arr2 = list(map(int, arr2))\n",
    "    \n",
    "    correct_predictions = sum((a in gr1 and b in  gr1) or (a in gr2 and b in  gr2) or (a in gr3 and b in  gr3)  for a, b in zip(arr1, arr2))\n",
    "    accuracy = correct_predictions / len(arr1)\n",
    "    return accuracy\n",
    "\n",
    "print(calculate_accuracy(predictions_labels, y_test_labels))\n",
    "# lstm 0.6\n",
    "# dense 0.61 for timestamp 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[3.]]),\n",
       " array([[0.16657583, 0.18264082, 0.3754841 , 0.18840069, 0.03018858,\n",
       "         0.04028865, 0.01642125]], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_last(last_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adil/miniconda3/envs/sphere-predictor-cj/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(path='../.models/cj_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[3.]]),\n",
       " array([[0.16657583, 0.18264082, 0.3754841 , 0.18840069, 0.03018858,\n",
       "         0.04028865, 0.01642125]], dtype=float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = CjModel()\n",
    "model2.load(path='../.models/cj_model')\n",
    "model2.predict_last(last_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
